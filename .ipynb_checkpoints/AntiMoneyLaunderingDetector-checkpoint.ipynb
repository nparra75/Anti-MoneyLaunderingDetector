{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Anti-Money Laundering Detector**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Installing the needed libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "from pyspark.sql import SparkSession\n",
    "import random\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType, DoubleType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, sum, when, count, avg, to_timestamp, hour, dayofweek\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.sql import Window\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.stat import Correlation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = \"C:/Users/Public/kaggle.json\"\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the dataset owner, the data is divided in 6 datasets into two groups of three:\n",
    "\n",
    "* Group HI has a relatively higher illicit ratio (more laundering).\n",
    "* Group LI has a relatively lower illicit ratio (less laundering).\n",
    "\n",
    "Both HI and LI internally have three sets of data: small, medium, and large. Also, provides two files for each of the six datasets:\n",
    "\n",
    "* A list of transactions in CSV format\n",
    "* A text file list of laundering transactions.\n",
    "\n",
    "So, we have a larga dataset, but for our project, we will use the following files:\n",
    "\n",
    "* HI-Medium_Trans.csv\n",
    "* HI-Medium_Patterns.txt\n",
    "* LI-Medium_Trans.csv\n",
    "* LI-Medium_Patterns.txt\n",
    "\n",
    "Transaction files and Pattern files, each they will be merged in a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml\n",
      "Dataset URL: https://www.kaggle.com/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml\n",
      "Dataset URL: https://www.kaggle.com/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml\n",
      "Dataset URL: https://www.kaggle.com/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m api\u001b[38;5;241m.\u001b[39mdataset_download_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mealtman2019/ibm-transactions-for-anti-money-laundering-aml\u001b[39m\u001b[38;5;124m'\u001b[39m, file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLI-Medium_Patterns.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Unzip the files (if zip extension)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset, file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfiles\u001b[49m: \n\u001b[0;32m      9\u001b[0m     api\u001b[38;5;241m.\u001b[39mdataset_download_file(dataset, file_name\u001b[38;5;241m=\u001b[39mfile_name, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m     10\u001b[0m     zip_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m'\u001b[39m \n",
      "\u001b[1;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "# Downloading the dataset from Kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Lista de archivos y sus rutas\n",
    "files = [\n",
    "    ('ealtman2019/ibm-transactions-for-anti-money-laundering-aml', 'HI-Medium_Trans.csv'),\n",
    "    ('ealtman2019/ibm-transactions-for-anti-money-laundering-aml', 'HI-Medium_Patterns.txt'),\n",
    "    ('ealtman2019/ibm-transactions-for-anti-money-laundering-aml', 'LI-Medium_Trans.csv'),\n",
    "    ('ealtman2019/ibm-transactions-for-anti-money-laundering-aml', 'LI-Medium_Patterns.txt'),\n",
    "]\n",
    "\n",
    "# Unzip the files (if zip extension)\n",
    "for dataset, file_name in files:\n",
    "    api.dataset_download_file(dataset, file_name=file_name, path='./dataset/')\n",
    "    zip_path = f'./dataset/{file_name}.zip'\n",
    "    if os.path.exists(zip_path):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall('./dataset/')\n",
    "        os.remove(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a SparkSession to manipulate the datasets\n",
    "spark = SparkSession.builder.appName(\"AML_Spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transactions Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for the transactions\n",
    "schema = StructType([\n",
    "    StructField(\"Timestamp\", StringType(), True),\n",
    "    StructField(\"From_Bank\", StringType(), True),\n",
    "    StructField(\"From_Account\", StringType(), True),\n",
    "    StructField(\"To_Bank\", StringType(), True),\n",
    "    StructField(\"To_Account\", StringType(), True),\n",
    "    StructField(\"Amount_Received\", FloatType(), True),\n",
    "    StructField(\"Receiving_Currency\", StringType(), True),\n",
    "    StructField(\"Amount_Paid\", FloatType(), True),\n",
    "    StructField(\"Payment_Currency\", StringType(), True),\n",
    "    StructField(\"Payment_Format\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Ilicit - Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/C:/Users/mgmig/Documents/Personal/Lambton College/2024F/Big Data Framework/Project/HI-Medium_Trans.csv.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read the CSV file into a Spark DataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m hi_medium_df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHI-Medium_Trans.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the DataFrame\u001b[39;00m\n\u001b[0;32m      5\u001b[0m hi_medium_df\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:740\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[1;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/C:/Users/mgmig/Documents/Personal/Lambton College/2024F/Big Data Framework/Project/HI-Medium_Trans.csv."
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a Spark DataFrame\n",
    "hi_medium_df = spark.read.csv(\"HI-Medium_Trans.csv\", schema=schema, header=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "hi_medium_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Ilicit - Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:30.801280Z",
     "iopub.status.busy": "2024-12-03T15:38:30.800733Z",
     "iopub.status.idle": "2024-12-03T15:38:31.250285Z",
     "shell.execute_reply": "2024-12-03T15:38:31.248258Z",
     "shell.execute_reply.started": "2024-12-03T15:38:30.801222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+------------+--------+----------+---------------+------------------+-----------+----------------+--------------+\n",
      "|       Timestamp|From_Bank|From_Account| To_Bank|To_Account|Amount_Received|Receiving_Currency|Amount_Paid|Payment_Currency|Payment_Format|\n",
      "+----------------+---------+------------+--------+----------+---------------+------------------+-----------+----------------+--------------+\n",
      "|2022/09/01 00:15|      020|   800104D70|     020| 800104D70|        8095.07|         US Dollar|    8095.07|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:18|    03196|   800107150|   03196| 800107150|        7739.29|         US Dollar|    7739.29|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:23|    01208|   80010E430|   01208| 80010E430|        2654.22|         US Dollar|    2654.22|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:19|    03203|   80010EA80|   03203| 80010EA80|       13284.41|         US Dollar|   13284.41|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:27|      020|   800104D20|     020| 800104D20|           9.72|         US Dollar|       9.72|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:29|      020|   800104D70|     020| 800104D70|           5.38|         US Dollar|       5.38|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:08|    01208|   80010E430|   01208| 80010E430|           7.66|         US Dollar|       7.66|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:29|      011|   80010E600|     011| 80010E600|          16.33|         US Dollar|      16.33|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:23|    01208|   80010E650|   01208| 80010E650|           4.86|         US Dollar|       4.86|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:15|      020|   80010E6F0|  027365| 8084250A0|         137.72|         US Dollar|     137.72|       US Dollar|   Credit Card|\n",
      "|2022/09/01 00:05|      020|   80010EA30|  018234| 82BC4CE30|           1.24|         US Dollar|       1.24|       US Dollar|   Credit Card|\n",
      "|2022/09/01 00:20|      020|   800073020|     020| 800073020|      848901.75|         US Dollar|  848901.75|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:02|    03566|   800345920|   03566| 800345920|       10134.05|         US Dollar|   10134.05|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:25|      011|   800329930|   02776| 800816450|      2602616.0|         US Dollar|  2602616.0|       US Dollar|        Cheque|\n",
      "|2022/09/01 00:27|      000|   8009B22F0|     000| 8009B22F0|        3236.71|         US Dollar|    3236.71|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:21|      011|   8003289F0| 0237264| 810BA3240|           5.28|         US Dollar|       5.28|       US Dollar|   Credit Card|\n",
      "|2022/09/01 00:29|      011|   800329930|     011| 800329930|          23.39|         US Dollar|      23.39|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:18|      000|   800815DE0|     000| 800815DE0|          19.97|         US Dollar|      19.97|       US Dollar|  Reinvestment|\n",
      "|2022/09/01 00:11|    02776|   800816450|01190218| 8486D8D10|          13.21|         US Dollar|      13.21|       US Dollar|   Credit Card|\n",
      "|2022/09/01 00:24|   011081|   8008DDDF0|  011081| 8008DDDF0|          13.87|         US Dollar|      13.87|       US Dollar|  Reinvestment|\n",
      "+----------------+---------+------------+--------+----------+---------------+------------------+-----------+----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:38:31 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 11, schema size: 10\n",
      "CSV file: file:///kaggle/input/ibm-transactions-for-anti-money-laundering-aml/LI-Medium_Trans.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a Spark DataFrame\n",
    "li_medium_df = spark.read.csv(\"LI-Medium_Trans.csv\", schema=schema, header=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "li_medium_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:31.252490Z",
     "iopub.status.busy": "2024-12-03T15:38:31.251965Z",
     "iopub.status.idle": "2024-12-03T15:38:31.297456Z",
     "shell.execute_reply": "2024-12-03T15:38:31.296013Z",
     "shell.execute_reply.started": "2024-12-03T15:38:31.252435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine both datasets\n",
    "trans_df = hi_medium_df.union(li_medium_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Patterns Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Ilicit - Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:31.300081Z",
     "iopub.status.busy": "2024-12-03T15:38:31.299207Z",
     "iopub.status.idle": "2024-12-03T15:38:31.631557Z",
     "shell.execute_reply": "2024-12-03T15:38:31.629572Z",
     "shell.execute_reply.started": "2024-12-03T15:38:31.300000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|BEGIN LAUNDERING ...|\n",
      "|2022/09/01 05:14,...|\n",
      "|2022/09/03 13:09,...|\n",
      "|2022/09/01 07:40,...|\n",
      "|2022/09/01 14:19,...|\n",
      "|2022/09/02 12:40,...|\n",
      "|2022/09/03 06:34,...|\n",
      "|END LAUNDERING AT...|\n",
      "|                    |\n",
      "|BEGIN LAUNDERING ...|\n",
      "|2022/09/01 00:19,...|\n",
      "|2022/09/01 19:35,...|\n",
      "|2022/09/02 02:58,...|\n",
      "|2022/09/02 18:02,...|\n",
      "|2022/09/03 07:16,...|\n",
      "|2022/09/03 11:39,...|\n",
      "|2022/09/03 12:04,...|\n",
      "|2022/09/04 07:27,...|\n",
      "|2022/09/04 08:38,...|\n",
      "|2022/09/05 13:23,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the file into a Spark DataFrame\n",
    "hi_patterns_df = spark.read.text(\"HI-Medium_Patterns.txt\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "hi_patterns_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Ilicit - Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:31.635544Z",
     "iopub.status.busy": "2024-12-03T15:38:31.634596Z",
     "iopub.status.idle": "2024-12-03T15:38:31.854240Z",
     "shell.execute_reply": "2024-12-03T15:38:31.853152Z",
     "shell.execute_reply.started": "2024-12-03T15:38:31.635488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|BEGIN LAUNDERING ...|\n",
      "|2022/09/01 00:29,...|\n",
      "|2022/09/04 12:49,...|\n",
      "|2022/09/01 12:28,...|\n",
      "|2022/09/04 13:39,...|\n",
      "|2022/09/01 14:26,...|\n",
      "|2022/09/04 15:34,...|\n",
      "|2022/09/02 15:52,...|\n",
      "|2022/09/04 16:27,...|\n",
      "|2022/09/02 17:41,...|\n",
      "|2022/09/05 08:36,...|\n",
      "|2022/09/03 08:04,...|\n",
      "|2022/09/05 13:36,...|\n",
      "|2022/09/03 15:18,...|\n",
      "|2022/09/05 15:45,...|\n",
      "|2022/09/03 16:50,...|\n",
      "|2022/09/05 16:00,...|\n",
      "|2022/09/03 22:43,...|\n",
      "|2022/09/05 17:50,...|\n",
      "|2022/09/03 23:22,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the file into a Spark DataFrame\n",
    "li_patterns_df = spark.read.text(\"LI-Medium_Patterns.txt\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "li_patterns_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:31.863180Z",
     "iopub.status.busy": "2024-12-03T15:38:31.862531Z",
     "iopub.status.idle": "2024-12-03T15:38:31.877985Z",
     "shell.execute_reply": "2024-12-03T15:38:31.875960Z",
     "shell.execute_reply.started": "2024-12-03T15:38:31.863124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine both datasets\n",
    "patterns_df = hi_patterns_df.union(li_patterns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PreProcessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Laundering Patterns:\n",
    "Each laundering attempt begins with BEGIN LAUNDERING ATTEMPT - [PATTERN] and ends with END LAUNDERING ATTEMPT.\n",
    "\n",
    "Used regex to extract pattern types and transaction details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:31.880656Z",
     "iopub.status.busy": "2024-12-03T15:38:31.880146Z",
     "iopub.status.idle": "2024-12-03T15:38:32.130099Z",
     "shell.execute_reply": "2024-12-03T15:38:32.128529Z",
     "shell.execute_reply.started": "2024-12-03T15:38:31.880606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Extract Pattern_Type where there is \"BEGIN LAUNDERING ATTEMPT\"\n",
    "patterns_df = patterns_df.withColumn(\n",
    "    \"Pattern_Type\",\n",
    "    F.when(F.col(\"value\").rlike(\"BEGIN LAUNDERING ATTEMPT - (.+)\"),\n",
    "           F.regexp_extract(F.col(\"value\"), \"BEGIN LAUNDERING ATTEMPT - (.+)\", 1))\n",
    "     .otherwise(None)\n",
    ")\n",
    "\n",
    "# Step 2: Forward fill the Pattern_Type to propagate it down until \"END LAUNDERING ATTEMPT\"\n",
    "window_spec = Window.orderBy(F.monotonically_increasing_id()).rowsBetween(Window.unboundedPreceding, 0)\n",
    "patterns_df = patterns_df.withColumn(\n",
    "    \"Pattern_Type\",\n",
    "    F.last(\"Pattern_Type\", True).over(window_spec)\n",
    ")\n",
    "\n",
    "# Step 3: Filter out rows with \"END LAUNDERING ATTEMPT\" as they only mark the end of an attempt\n",
    "patterns_df = patterns_df.filter(~F.col(\"value\").contains(\"END LAUNDERING ATTEMPT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:32.132487Z",
     "iopub.status.busy": "2024-12-03T15:38:32.131508Z",
     "iopub.status.idle": "2024-12-03T15:38:34.330859Z",
     "shell.execute_reply": "2024-12-03T15:38:34.327449Z",
     "shell.execute_reply.started": "2024-12-03T15:38:32.132428Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:38:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/03 15:38:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/03 15:38:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/03 15:38:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/03 15:38:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+-------------------+\n",
      "|value                                                                                           |Pattern_Type       |\n",
      "+------------------------------------------------------------------------------------------------+-------------------+\n",
      "|BEGIN LAUNDERING ATTEMPT - STACK                                                                |STACK              |\n",
      "|2022/09/01 05:14,00952,8139F54E0,0111632,8062C56E0,5331.44,US Dollar,5331.44,US Dollar,ACH,1    |STACK              |\n",
      "|2022/09/03 13:09,0111632,8062C56E0,008456,81363F620,5602.59,US Dollar,5602.59,US Dollar,ACH,1   |STACK              |\n",
      "|2022/09/01 07:40,0118693,823D5EB90,013729,801CF2E60,1400.54,US Dollar,1400.54,US Dollar,ACH,1   |STACK              |\n",
      "|2022/09/01 14:19,013729,801CF2E60,0123621,81A7090F0,1467.94,US Dollar,1467.94,US Dollar,ACH,1   |STACK              |\n",
      "|2022/09/02 12:40,0024750,81363F410,0213834,808757B00,16898.29,US Dollar,16898.29,US Dollar,ACH,1|STACK              |\n",
      "|2022/09/03 06:34,0213834,808757B00,000,800073EF0,17607.19,US Dollar,17607.19,US Dollar,ACH,1    |STACK              |\n",
      "|                                                                                                |STACK              |\n",
      "|BEGIN LAUNDERING ATTEMPT - CYCLE:  Max 12 hops                                                  |CYCLE:  Max 12 hops|\n",
      "|2022/09/01 00:19,0134266,814167590,0036925,810E343A0,132713.46,Yuan,132713.46,Yuan,ACH,1        |CYCLE:  Max 12 hops|\n",
      "|2022/09/01 19:35,0036925,810E343A0,0119211,814AB4F60,18264.20,US Dollar,18264.20,US Dollar,ACH,1|CYCLE:  Max 12 hops|\n",
      "|2022/09/02 02:58,0119211,814AB4F60,0132965,81B88A230,14567.69,Euro,14567.69,Euro,ACH,1          |CYCLE:  Max 12 hops|\n",
      "|2022/09/02 18:02,0132965,81B88A230,0137089,810C71940,114329.26,Yuan,114329.26,Yuan,ACH,1        |CYCLE:  Max 12 hops|\n",
      "|2022/09/03 07:16,0137089,810C71940,0216618,81D5302D0,14567.69,Euro,14567.69,Euro,ACH,1          |CYCLE:  Max 12 hops|\n",
      "|2022/09/03 11:39,0216618,81D5302D0,0024083,81836B520,13629.75,Euro,13629.75,Euro,ACH,1          |CYCLE:  Max 12 hops|\n",
      "|2022/09/03 12:04,0024083,81836B520,0038110,81B868730,97481.96,Yuan,97481.96,Yuan,ACH,1          |CYCLE:  Max 12 hops|\n",
      "|2022/09/04 07:27,0038110,81B868730,0225015,81C6EA460,14054.71,US Dollar,14054.71,US Dollar,ACH,1|CYCLE:  Max 12 hops|\n",
      "|2022/09/04 08:38,0225015,81C6EA460,018112,8045CC910,13718.22,US Dollar,13718.22,US Dollar,ACH,1 |CYCLE:  Max 12 hops|\n",
      "|2022/09/05 13:23,018112,8045CC910,007818,8037732C0,12908.33,US Dollar,12908.33,US Dollar,ACH,1  |CYCLE:  Max 12 hops|\n",
      "|2022/09/06 05:10,007818,8037732C0,0121523,80D1BD2F0,10636.75,Euro,10636.75,Euro,ACH,1           |CYCLE:  Max 12 hops|\n",
      "+------------------------------------------------------------------------------------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show the DataFrame without truncating long strings\n",
    "patterns_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:34.335746Z",
     "iopub.status.busy": "2024-12-03T15:38:34.335213Z",
     "iopub.status.idle": "2024-12-03T15:38:35.016103Z",
     "shell.execute_reply": "2024-12-03T15:38:35.014548Z",
     "shell.execute_reply.started": "2024-12-03T15:38:34.335693Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:38:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/03 15:38:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/03 15:38:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/03 15:38:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/03 15:38:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+------------+\n",
      "|value                                                                                           |Pattern_Type|\n",
      "+------------------------------------------------------------------------------------------------+------------+\n",
      "|BEGIN LAUNDERING ATTEMPT - STACK                                                                |STACK       |\n",
      "|2022/09/01 05:14,00952,8139F54E0,0111632,8062C56E0,5331.44,US Dollar,5331.44,US Dollar,ACH,1    |STACK       |\n",
      "|2022/09/03 13:09,0111632,8062C56E0,008456,81363F620,5602.59,US Dollar,5602.59,US Dollar,ACH,1   |STACK       |\n",
      "|2022/09/01 07:40,0118693,823D5EB90,013729,801CF2E60,1400.54,US Dollar,1400.54,US Dollar,ACH,1   |STACK       |\n",
      "|2022/09/01 14:19,013729,801CF2E60,0123621,81A7090F0,1467.94,US Dollar,1467.94,US Dollar,ACH,1   |STACK       |\n",
      "|2022/09/02 12:40,0024750,81363F410,0213834,808757B00,16898.29,US Dollar,16898.29,US Dollar,ACH,1|STACK       |\n",
      "|2022/09/03 06:34,0213834,808757B00,000,800073EF0,17607.19,US Dollar,17607.19,US Dollar,ACH,1    |STACK       |\n",
      "|                                                                                                |STACK       |\n",
      "|BEGIN LAUNDERING ATTEMPT - CYCLE:  Max 12 hops                                                  |CYCLE       |\n",
      "|2022/09/01 00:19,0134266,814167590,0036925,810E343A0,132713.46,Yuan,132713.46,Yuan,ACH,1        |CYCLE       |\n",
      "|2022/09/01 19:35,0036925,810E343A0,0119211,814AB4F60,18264.20,US Dollar,18264.20,US Dollar,ACH,1|CYCLE       |\n",
      "|2022/09/02 02:58,0119211,814AB4F60,0132965,81B88A230,14567.69,Euro,14567.69,Euro,ACH,1          |CYCLE       |\n",
      "|2022/09/02 18:02,0132965,81B88A230,0137089,810C71940,114329.26,Yuan,114329.26,Yuan,ACH,1        |CYCLE       |\n",
      "|2022/09/03 07:16,0137089,810C71940,0216618,81D5302D0,14567.69,Euro,14567.69,Euro,ACH,1          |CYCLE       |\n",
      "|2022/09/03 11:39,0216618,81D5302D0,0024083,81836B520,13629.75,Euro,13629.75,Euro,ACH,1          |CYCLE       |\n",
      "|2022/09/03 12:04,0024083,81836B520,0038110,81B868730,97481.96,Yuan,97481.96,Yuan,ACH,1          |CYCLE       |\n",
      "|2022/09/04 07:27,0038110,81B868730,0225015,81C6EA460,14054.71,US Dollar,14054.71,US Dollar,ACH,1|CYCLE       |\n",
      "|2022/09/04 08:38,0225015,81C6EA460,018112,8045CC910,13718.22,US Dollar,13718.22,US Dollar,ACH,1 |CYCLE       |\n",
      "|2022/09/05 13:23,018112,8045CC910,007818,8037732C0,12908.33,US Dollar,12908.33,US Dollar,ACH,1  |CYCLE       |\n",
      "|2022/09/06 05:10,007818,8037732C0,0121523,80D1BD2F0,10636.75,Euro,10636.75,Euro,ACH,1           |CYCLE       |\n",
      "+------------------------------------------------------------------------------------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Remove any text after the colon in Pattern_Type if it exists\n",
    "patterns_df = patterns_df.withColumn(\n",
    "    \"Pattern_Type\",\n",
    "    F.regexp_replace(F.col(\"Pattern_Type\"), \":.*\", \"\")\n",
    ")\n",
    "\n",
    "# Display the DataFrame (use .show() in local PySpark)\n",
    "patterns_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:35.019775Z",
     "iopub.status.busy": "2024-12-03T15:38:35.019120Z",
     "iopub.status.idle": "2024-12-03T15:38:36.544149Z",
     "shell.execute_reply": "2024-12-03T15:38:36.540199Z",
     "shell.execute_reply.started": "2024-12-03T15:38:35.019717Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:38:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/03 15:38:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/03 15:38:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/03 15:38:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/03 15:38:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+------------+\n",
      "|value                                                                                           |Pattern_Type|\n",
      "+------------------------------------------------------------------------------------------------+------------+\n",
      "|2022/09/01 05:14,00952,8139F54E0,0111632,8062C56E0,5331.44,US Dollar,5331.44,US Dollar,ACH,1    |STACK       |\n",
      "|2022/09/03 13:09,0111632,8062C56E0,008456,81363F620,5602.59,US Dollar,5602.59,US Dollar,ACH,1   |STACK       |\n",
      "|2022/09/01 07:40,0118693,823D5EB90,013729,801CF2E60,1400.54,US Dollar,1400.54,US Dollar,ACH,1   |STACK       |\n",
      "|2022/09/01 14:19,013729,801CF2E60,0123621,81A7090F0,1467.94,US Dollar,1467.94,US Dollar,ACH,1   |STACK       |\n",
      "|2022/09/02 12:40,0024750,81363F410,0213834,808757B00,16898.29,US Dollar,16898.29,US Dollar,ACH,1|STACK       |\n",
      "|2022/09/03 06:34,0213834,808757B00,000,800073EF0,17607.19,US Dollar,17607.19,US Dollar,ACH,1    |STACK       |\n",
      "|2022/09/01 00:19,0134266,814167590,0036925,810E343A0,132713.46,Yuan,132713.46,Yuan,ACH,1        |CYCLE       |\n",
      "|2022/09/01 19:35,0036925,810E343A0,0119211,814AB4F60,18264.20,US Dollar,18264.20,US Dollar,ACH,1|CYCLE       |\n",
      "|2022/09/02 02:58,0119211,814AB4F60,0132965,81B88A230,14567.69,Euro,14567.69,Euro,ACH,1          |CYCLE       |\n",
      "|2022/09/02 18:02,0132965,81B88A230,0137089,810C71940,114329.26,Yuan,114329.26,Yuan,ACH,1        |CYCLE       |\n",
      "|2022/09/03 07:16,0137089,810C71940,0216618,81D5302D0,14567.69,Euro,14567.69,Euro,ACH,1          |CYCLE       |\n",
      "|2022/09/03 11:39,0216618,81D5302D0,0024083,81836B520,13629.75,Euro,13629.75,Euro,ACH,1          |CYCLE       |\n",
      "|2022/09/03 12:04,0024083,81836B520,0038110,81B868730,97481.96,Yuan,97481.96,Yuan,ACH,1          |CYCLE       |\n",
      "|2022/09/04 07:27,0038110,81B868730,0225015,81C6EA460,14054.71,US Dollar,14054.71,US Dollar,ACH,1|CYCLE       |\n",
      "|2022/09/04 08:38,0225015,81C6EA460,018112,8045CC910,13718.22,US Dollar,13718.22,US Dollar,ACH,1 |CYCLE       |\n",
      "|2022/09/05 13:23,018112,8045CC910,007818,8037732C0,12908.33,US Dollar,12908.33,US Dollar,ACH,1  |CYCLE       |\n",
      "|2022/09/06 05:10,007818,8037732C0,0121523,80D1BD2F0,10636.75,Euro,10636.75,Euro,ACH,1           |CYCLE       |\n",
      "|2022/09/06 13:24,0121523,80D1BD2F0,0134266,814167590,1378736.88,Yen,1378736.88,Yen,ACH,1        |CYCLE       |\n",
      "|2022/09/01 00:25,0266915,81C3CD2E0,0266946,81A4AFE20,1155546.44,Ruble,1155546.44,Ruble,ACH,1    |FAN-IN      |\n",
      "|2022/09/01 03:18,0174634,81C5B2AB0,0266946,81A4AFE20,1104862.69,Ruble,1104862.69,Ruble,ACH,1    |FAN-IN      |\n",
      "+------------------------------------------------------------------------------------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Filter to get only transaction lines and ignore start/end laundering attempt lines\n",
    "laundering_transactions = patterns_df.filter(patterns_df.value.rlike(r'\\d{4}/\\d{2}/\\d{2}'))\n",
    "\n",
    "# Unpersist patterns_df to free memory\n",
    "patterns_df.unpersist()\n",
    "\n",
    "# Cache laundering_transactions for reuse\n",
    "laundering_transactions.cache()\n",
    "\n",
    "# Display the filtered DataFrame (use .show() instead of display())\n",
    "laundering_transactions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:36.546582Z",
     "iopub.status.busy": "2024-12-03T15:38:36.546109Z",
     "iopub.status.idle": "2024-12-03T15:38:36.856417Z",
     "shell.execute_reply": "2024-12-03T15:38:36.855214Z",
     "shell.execute_reply.started": "2024-12-03T15:38:36.546532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Updated Code for Better Readability\n",
    "columns = [\n",
    "    \"Timestamp\", \"From_Bank\", \"From_Account\", \"To_Bank\", \"To_Account\",\n",
    "    \"Amount_Received\", \"Receiving_currency\", \"Amount_paid\",\n",
    "    \"Payment_currency\", \"Payment_Format\", \"isLaundering\"\n",
    "]\n",
    "\n",
    "for idx, col_name in enumerate(columns):\n",
    "    laundering_transactions = laundering_transactions.withColumn(col_name, F.split(F.col(\"value\"), \",\").getItem(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:36.862446Z",
     "iopub.status.busy": "2024-12-03T15:38:36.860366Z",
     "iopub.status.idle": "2024-12-03T15:38:37.223318Z",
     "shell.execute_reply": "2024-12-03T15:38:37.222235Z",
     "shell.execute_reply.started": "2024-12-03T15:38:36.862377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+------------+----------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+\n",
      "|value                                                                                           |Pattern_Type|Timestamp       |From_Bank|From_Account|To_Bank|To_Account|Amount_Received|Receiving_currency|Amount_paid|Payment_currency|Payment_Format|isLaundering|\n",
      "+------------------------------------------------------------------------------------------------+------------+----------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+\n",
      "|2022/09/01 05:14,00952,8139F54E0,0111632,8062C56E0,5331.44,US Dollar,5331.44,US Dollar,ACH,1    |STACK       |2022/09/01 05:14|00952    |8139F54E0   |0111632|8062C56E0 |5331.44        |US Dollar         |5331.44    |US Dollar       |ACH           |1           |\n",
      "|2022/09/03 13:09,0111632,8062C56E0,008456,81363F620,5602.59,US Dollar,5602.59,US Dollar,ACH,1   |STACK       |2022/09/03 13:09|0111632  |8062C56E0   |008456 |81363F620 |5602.59        |US Dollar         |5602.59    |US Dollar       |ACH           |1           |\n",
      "|2022/09/01 07:40,0118693,823D5EB90,013729,801CF2E60,1400.54,US Dollar,1400.54,US Dollar,ACH,1   |STACK       |2022/09/01 07:40|0118693  |823D5EB90   |013729 |801CF2E60 |1400.54        |US Dollar         |1400.54    |US Dollar       |ACH           |1           |\n",
      "|2022/09/01 14:19,013729,801CF2E60,0123621,81A7090F0,1467.94,US Dollar,1467.94,US Dollar,ACH,1   |STACK       |2022/09/01 14:19|013729   |801CF2E60   |0123621|81A7090F0 |1467.94        |US Dollar         |1467.94    |US Dollar       |ACH           |1           |\n",
      "|2022/09/02 12:40,0024750,81363F410,0213834,808757B00,16898.29,US Dollar,16898.29,US Dollar,ACH,1|STACK       |2022/09/02 12:40|0024750  |81363F410   |0213834|808757B00 |16898.29       |US Dollar         |16898.29   |US Dollar       |ACH           |1           |\n",
      "|2022/09/03 06:34,0213834,808757B00,000,800073EF0,17607.19,US Dollar,17607.19,US Dollar,ACH,1    |STACK       |2022/09/03 06:34|0213834  |808757B00   |000    |800073EF0 |17607.19       |US Dollar         |17607.19   |US Dollar       |ACH           |1           |\n",
      "|2022/09/01 00:19,0134266,814167590,0036925,810E343A0,132713.46,Yuan,132713.46,Yuan,ACH,1        |CYCLE       |2022/09/01 00:19|0134266  |814167590   |0036925|810E343A0 |132713.46      |Yuan              |132713.46  |Yuan            |ACH           |1           |\n",
      "|2022/09/01 19:35,0036925,810E343A0,0119211,814AB4F60,18264.20,US Dollar,18264.20,US Dollar,ACH,1|CYCLE       |2022/09/01 19:35|0036925  |810E343A0   |0119211|814AB4F60 |18264.20       |US Dollar         |18264.20   |US Dollar       |ACH           |1           |\n",
      "|2022/09/02 02:58,0119211,814AB4F60,0132965,81B88A230,14567.69,Euro,14567.69,Euro,ACH,1          |CYCLE       |2022/09/02 02:58|0119211  |814AB4F60   |0132965|81B88A230 |14567.69       |Euro              |14567.69   |Euro            |ACH           |1           |\n",
      "|2022/09/02 18:02,0132965,81B88A230,0137089,810C71940,114329.26,Yuan,114329.26,Yuan,ACH,1        |CYCLE       |2022/09/02 18:02|0132965  |81B88A230   |0137089|810C71940 |114329.26      |Yuan              |114329.26  |Yuan            |ACH           |1           |\n",
      "|2022/09/03 07:16,0137089,810C71940,0216618,81D5302D0,14567.69,Euro,14567.69,Euro,ACH,1          |CYCLE       |2022/09/03 07:16|0137089  |810C71940   |0216618|81D5302D0 |14567.69       |Euro              |14567.69   |Euro            |ACH           |1           |\n",
      "|2022/09/03 11:39,0216618,81D5302D0,0024083,81836B520,13629.75,Euro,13629.75,Euro,ACH,1          |CYCLE       |2022/09/03 11:39|0216618  |81D5302D0   |0024083|81836B520 |13629.75       |Euro              |13629.75   |Euro            |ACH           |1           |\n",
      "|2022/09/03 12:04,0024083,81836B520,0038110,81B868730,97481.96,Yuan,97481.96,Yuan,ACH,1          |CYCLE       |2022/09/03 12:04|0024083  |81836B520   |0038110|81B868730 |97481.96       |Yuan              |97481.96   |Yuan            |ACH           |1           |\n",
      "|2022/09/04 07:27,0038110,81B868730,0225015,81C6EA460,14054.71,US Dollar,14054.71,US Dollar,ACH,1|CYCLE       |2022/09/04 07:27|0038110  |81B868730   |0225015|81C6EA460 |14054.71       |US Dollar         |14054.71   |US Dollar       |ACH           |1           |\n",
      "|2022/09/04 08:38,0225015,81C6EA460,018112,8045CC910,13718.22,US Dollar,13718.22,US Dollar,ACH,1 |CYCLE       |2022/09/04 08:38|0225015  |81C6EA460   |018112 |8045CC910 |13718.22       |US Dollar         |13718.22   |US Dollar       |ACH           |1           |\n",
      "|2022/09/05 13:23,018112,8045CC910,007818,8037732C0,12908.33,US Dollar,12908.33,US Dollar,ACH,1  |CYCLE       |2022/09/05 13:23|018112   |8045CC910   |007818 |8037732C0 |12908.33       |US Dollar         |12908.33   |US Dollar       |ACH           |1           |\n",
      "|2022/09/06 05:10,007818,8037732C0,0121523,80D1BD2F0,10636.75,Euro,10636.75,Euro,ACH,1           |CYCLE       |2022/09/06 05:10|007818   |8037732C0   |0121523|80D1BD2F0 |10636.75       |Euro              |10636.75   |Euro            |ACH           |1           |\n",
      "|2022/09/06 13:24,0121523,80D1BD2F0,0134266,814167590,1378736.88,Yen,1378736.88,Yen,ACH,1        |CYCLE       |2022/09/06 13:24|0121523  |80D1BD2F0   |0134266|814167590 |1378736.88     |Yen               |1378736.88 |Yen             |ACH           |1           |\n",
      "|2022/09/01 00:25,0266915,81C3CD2E0,0266946,81A4AFE20,1155546.44,Ruble,1155546.44,Ruble,ACH,1    |FAN-IN      |2022/09/01 00:25|0266915  |81C3CD2E0   |0266946|81A4AFE20 |1155546.44     |Ruble             |1155546.44 |Ruble           |ACH           |1           |\n",
      "|2022/09/01 03:18,0174634,81C5B2AB0,0266946,81A4AFE20,1104862.69,Ruble,1104862.69,Ruble,ACH,1    |FAN-IN      |2022/09/01 03:18|0174634  |81C5B2AB0   |0266946|81A4AFE20 |1104862.69     |Ruble             |1104862.69 |Ruble           |ACH           |1           |\n",
      "+------------------------------------------------------------------------------------------------+------------+----------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "laundering_transactions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:37.225123Z",
     "iopub.status.busy": "2024-12-03T15:38:37.224612Z",
     "iopub.status.idle": "2024-12-03T15:38:37.585914Z",
     "shell.execute_reply": "2024-12-03T15:38:37.584135Z",
     "shell.execute_reply.started": "2024-12-03T15:38:37.225070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+------------+------------+\n",
      "|Timestamp       |From_Bank|Pattern_Type|isLaundering|\n",
      "+----------------+---------+------------+------------+\n",
      "|2022/09/01 05:14|00952    |STACK       |1           |\n",
      "|2022/09/03 13:09|0111632  |STACK       |1           |\n",
      "|2022/09/01 07:40|0118693  |STACK       |1           |\n",
      "|2022/09/01 14:19|013729   |STACK       |1           |\n",
      "|2022/09/02 12:40|0024750  |STACK       |1           |\n",
      "|2022/09/03 06:34|0213834  |STACK       |1           |\n",
      "|2022/09/01 00:19|0134266  |CYCLE       |1           |\n",
      "|2022/09/01 19:35|0036925  |CYCLE       |1           |\n",
      "|2022/09/02 02:58|0119211  |CYCLE       |1           |\n",
      "|2022/09/02 18:02|0132965  |CYCLE       |1           |\n",
      "|2022/09/03 07:16|0137089  |CYCLE       |1           |\n",
      "|2022/09/03 11:39|0216618  |CYCLE       |1           |\n",
      "|2022/09/03 12:04|0024083  |CYCLE       |1           |\n",
      "|2022/09/04 07:27|0038110  |CYCLE       |1           |\n",
      "|2022/09/04 08:38|0225015  |CYCLE       |1           |\n",
      "|2022/09/05 13:23|018112   |CYCLE       |1           |\n",
      "|2022/09/06 05:10|007818   |CYCLE       |1           |\n",
      "|2022/09/06 13:24|0121523  |CYCLE       |1           |\n",
      "|2022/09/01 00:25|0266915  |FAN-IN      |1           |\n",
      "|2022/09/01 03:18|0174634  |FAN-IN      |1           |\n",
      "+----------------+---------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "laundering_transactions = laundering_transactions.select(\"Timestamp\", \"From_Bank\", \"Pattern_Type\", \"isLaundering\")\n",
    "\n",
    "#  Display the results\n",
    "laundering_transactions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:37.587779Z",
     "iopub.status.busy": "2024-12-03T15:38:37.587315Z",
     "iopub.status.idle": "2024-12-03T15:38:38.224294Z",
     "shell.execute_reply": "2024-12-03T15:38:38.223186Z",
     "shell.execute_reply.started": "2024-12-03T15:38:37.587727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------+------------+\n",
      "|Timestamp|From_Bank|Pattern_Type|isLaundering|\n",
      "+---------+---------+------------+------------+\n",
      "|0        |0        |0           |0           |\n",
      "+---------+---------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count empty strings in each column\n",
    "empty_string_counts = laundering_transactions.select(\n",
    "    [sum(when(col(c) == \"\", 1).otherwise(0)).alias(c) for c in laundering_transactions.columns])\n",
    "\n",
    "# Show the result\n",
    "empty_string_counts.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:38.230615Z",
     "iopub.status.busy": "2024-12-03T15:38:38.229281Z",
     "iopub.status.idle": "2024-12-03T15:38:38.301343Z",
     "shell.execute_reply": "2024-12-03T15:38:38.299860Z",
     "shell.execute_reply.started": "2024-12-03T15:38:38.230535Z"
    }
   },
   "outputs": [],
   "source": [
    "laundering_transactions.createOrReplaceTempView(\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:38.303892Z",
     "iopub.status.busy": "2024-12-03T15:38:38.303371Z",
     "iopub.status.idle": "2024-12-03T15:38:38.882625Z",
     "shell.execute_reply": "2024-12-03T15:38:38.879586Z",
     "shell.execute_reply.started": "2024-12-03T15:38:38.303838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Pattern_Type  |count|\n",
      "+--------------+-----+\n",
      "|STACK         |4601 |\n",
      "|CYCLE         |2518 |\n",
      "|FAN-IN        |2644 |\n",
      "|GATHER-SCATTER|4830 |\n",
      "|BIPARTITE     |2623 |\n",
      "|FAN-OUT       |2617 |\n",
      "|SCATTER-GATHER|4874 |\n",
      "|RANDOM        |1945 |\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using spark.sql()\n",
    "result_df = spark.sql(\"\"\"\n",
    "    SELECT Pattern_Type, COUNT(Pattern_Type) AS count\n",
    "    FROM combined\n",
    "    GROUP BY Pattern_Type\n",
    "\"\"\")\n",
    "\n",
    "# Show the result\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:38.885548Z",
     "iopub.status.busy": "2024-12-03T15:38:38.884037Z",
     "iopub.status.idle": "2024-12-03T15:38:39.799933Z",
     "shell.execute_reply": "2024-12-03T15:38:39.798835Z",
     "shell.execute_reply.started": "2024-12-03T15:38:38.885484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|isLaundering|count|\n",
      "+------------+-----+\n",
      "|           1|26652|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "laundering_transactions.cache().groupBy(\"isLaundering\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Laundering Transactions Labeling**\n",
    "\n",
    "Joined the laundering pattern DataFrame (laundering_transactions) with the combined transaction DataFrame (trans_df) on transaction identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:39.802282Z",
     "iopub.status.busy": "2024-12-03T15:38:39.801777Z",
     "iopub.status.idle": "2024-12-03T15:38:39.916500Z",
     "shell.execute_reply": "2024-12-03T15:38:39.915074Z",
     "shell.execute_reply.started": "2024-12-03T15:38:39.802223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Timestamp: string, From_Bank: string, Pattern_Type: string, isLaundering: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the DataFrames on Timestamp, From_Bank, and To_Bank\n",
    "joined_df = trans_df.join(\n",
    "    laundering_transactions,\n",
    "    on=[\"Timestamp\", \"From_Bank\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Freeing from cache\n",
    "trans_df.unpersist()\n",
    "laundering_transactions.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:39.919081Z",
     "iopub.status.busy": "2024-12-03T15:38:39.918560Z",
     "iopub.status.idle": "2024-12-03T15:38:39.971192Z",
     "shell.execute_reply": "2024-12-03T15:38:39.970084Z",
     "shell.execute_reply.started": "2024-12-03T15:38:39.919012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill null values in the `isLaundering` column with 0\n",
    "joined_df = joined_df.withColumn(\n",
    "    \"isLaundering\",\n",
    "    F.when(F.col(\"isLaundering\").isNull(), F.lit(0)).otherwise(F.col(\"isLaundering\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:38:39.975088Z",
     "iopub.status.busy": "2024-12-03T15:38:39.974595Z",
     "iopub.status.idle": "2024-12-03T15:51:06.035533Z",
     "shell.execute_reply": "2024-12-03T15:51:06.031547Z",
     "shell.execute_reply.started": "2024-12-03T15:38:39.975023Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:38:41 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 11, schema size: 10\n",
      "CSV file: file:///kaggle/input/ibm-transactions-for-anti-money-laundering-aml/HI-Medium_Trans.csv\n",
      "24/12/03 15:40:37 WARN MemoryStore: Not enough space to cache rdd_107_4 in memory! (computed 44.3 MiB so far)\n",
      "24/12/03 15:40:37 WARN BlockManager: Persisting block rdd_107_4 to disk instead.\n",
      "24/12/03 15:40:50 WARN MemoryStore: Not enough space to cache rdd_107_4 in memory! (computed 6.7 MiB so far)\n",
      "24/12/03 15:41:00 WARN MemoryStore: Not enough space to cache rdd_107_10 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:41:00 WARN BlockManager: Persisting block rdd_107_10 to disk instead.\n",
      "24/12/03 15:41:00 WARN MemoryStore: Not enough space to cache rdd_107_11 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:41:00 WARN BlockManager: Persisting block rdd_107_11 to disk instead.\n",
      "24/12/03 15:41:05 WARN MemoryStore: Not enough space to cache rdd_107_8 in memory! (computed 12.4 MiB so far)\n",
      "24/12/03 15:41:05 WARN BlockManager: Persisting block rdd_107_8 to disk instead.\n",
      "24/12/03 15:41:13 WARN MemoryStore: Not enough space to cache rdd_107_9 in memory! (computed 19.6 MiB so far)\n",
      "24/12/03 15:41:13 WARN BlockManager: Persisting block rdd_107_9 to disk instead.\n",
      "24/12/03 15:41:55 WARN MemoryStore: Not enough space to cache rdd_107_8 in memory! (computed 24.4 MiB so far)\n",
      "24/12/03 15:41:56 WARN MemoryStore: Not enough space to cache rdd_107_9 in memory! (computed 12.4 MiB so far)\n",
      "24/12/03 15:41:58 WARN MemoryStore: Not enough space to cache rdd_107_11 in memory! (computed 12.4 MiB so far)\n",
      "24/12/03 15:41:59 WARN MemoryStore: Not enough space to cache rdd_107_10 in memory! (computed 12.4 MiB so far)\n",
      "24/12/03 15:42:04 WARN MemoryStore: Not enough space to cache rdd_107_13 in memory! (computed 6.8 MiB so far)\n",
      "24/12/03 15:42:04 WARN BlockManager: Persisting block rdd_107_13 to disk instead.\n",
      "24/12/03 15:42:05 WARN MemoryStore: Not enough space to cache rdd_107_14 in memory! (computed 6.7 MiB so far)\n",
      "24/12/03 15:42:05 WARN BlockManager: Persisting block rdd_107_14 to disk instead.\n",
      "24/12/03 15:42:06 WARN MemoryStore: Not enough space to cache rdd_107_15 in memory! (computed 7.4 MiB so far)\n",
      "24/12/03 15:42:06 WARN BlockManager: Persisting block rdd_107_15 to disk instead.\n",
      "24/12/03 15:42:11 WARN MemoryStore: Not enough space to cache rdd_107_12 in memory! (computed 14.0 MiB so far)\n",
      "24/12/03 15:42:11 WARN BlockManager: Persisting block rdd_107_12 to disk instead.\n",
      "24/12/03 15:43:00 WARN MemoryStore: Not enough space to cache rdd_107_12 in memory! (computed 14.0 MiB so far)\n",
      "24/12/03 15:43:02 WARN MemoryStore: Not enough space to cache rdd_107_13 in memory! (computed 25.9 MiB so far)\n",
      "24/12/03 15:43:03 WARN MemoryStore: Not enough space to cache rdd_107_14 in memory! (computed 26.0 MiB so far)\n",
      "24/12/03 15:43:04 WARN MemoryStore: Not enough space to cache rdd_107_15 in memory! (computed 25.4 MiB so far)\n",
      "24/12/03 15:43:10 WARN MemoryStore: Not enough space to cache rdd_107_18 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:43:10 WARN BlockManager: Persisting block rdd_107_18 to disk instead.\n",
      "24/12/03 15:43:12 WARN MemoryStore: Not enough space to cache rdd_107_19 in memory! (computed 6.9 MiB so far)\n",
      "24/12/03 15:43:12 WARN BlockManager: Persisting block rdd_107_19 to disk instead.\n",
      "24/12/03 15:43:16 WARN MemoryStore: Not enough space to cache rdd_107_16 in memory! (computed 12.4 MiB so far)\n",
      "24/12/03 15:43:16 WARN BlockManager: Persisting block rdd_107_16 to disk instead.\n",
      "24/12/03 15:43:31 WARN MemoryStore: Not enough space to cache rdd_107_17 in memory! (computed 24.4 MiB so far)\n",
      "24/12/03 15:43:31 WARN BlockManager: Persisting block rdd_107_17 to disk instead.\n",
      "24/12/03 15:44:08 WARN MemoryStore: Not enough space to cache rdd_107_16 in memory! (computed 25.4 MiB so far)\n",
      "24/12/03 15:44:09 WARN MemoryStore: Not enough space to cache rdd_107_17 in memory! (computed 12.4 MiB so far)\n",
      "24/12/03 15:44:10 WARN MemoryStore: Not enough space to cache rdd_107_18 in memory! (computed 12.4 MiB so far)\n",
      "24/12/03 15:44:11 WARN MemoryStore: Not enough space to cache rdd_107_19 in memory! (computed 13.4 MiB so far)\n",
      "24/12/03 15:44:12 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 11, schema size: 10\n",
      "CSV file: file:///kaggle/input/ibm-transactions-for-anti-money-laundering-aml/LI-Medium_Trans.csv\n",
      "24/12/03 15:44:16 WARN MemoryStore: Not enough space to cache rdd_107_21 in memory! (computed 6.6 MiB so far)\n",
      "24/12/03 15:44:16 WARN BlockManager: Persisting block rdd_107_21 to disk instead.\n",
      "24/12/03 15:44:18 WARN MemoryStore: Not enough space to cache rdd_107_22 in memory! (computed 6.7 MiB so far)\n",
      "24/12/03 15:44:18 WARN BlockManager: Persisting block rdd_107_22 to disk instead.\n",
      "24/12/03 15:44:19 WARN MemoryStore: Not enough space to cache rdd_107_23 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:44:19 WARN BlockManager: Persisting block rdd_107_23 to disk instead.\n",
      "24/12/03 15:44:37 WARN MemoryStore: Not enough space to cache rdd_107_20 in memory! (computed 24.6 MiB so far)\n",
      "24/12/03 15:44:37 WARN BlockManager: Persisting block rdd_107_20 to disk instead.\n",
      "24/12/03 15:44:49 WARN MemoryStore: Not enough space to cache rdd_107_22 in memory! (computed 12.9 MiB so far)\n",
      "24/12/03 15:45:04 WARN MemoryStore: Not enough space to cache rdd_107_24 in memory! (computed 14.4 MiB so far)\n",
      "24/12/03 15:45:04 WARN BlockManager: Persisting block rdd_107_24 to disk instead.\n",
      "24/12/03 15:45:14 WARN MemoryStore: Not enough space to cache rdd_107_20 in memory! (computed 24.6 MiB so far)\n",
      "24/12/03 15:45:16 WARN MemoryStore: Not enough space to cache rdd_107_21 in memory! (computed 25.5 MiB so far)\n",
      "24/12/03 15:45:16 WARN MemoryStore: Not enough space to cache rdd_107_23 in memory! (computed 15.8 MiB so far)\n",
      "24/12/03 15:45:24 WARN MemoryStore: Not enough space to cache rdd_107_27 in memory! (computed 6.7 MiB so far)\n",
      "24/12/03 15:45:24 WARN BlockManager: Persisting block rdd_107_27 to disk instead.\n",
      "24/12/03 15:45:29 WARN MemoryStore: Not enough space to cache rdd_107_25 in memory! (computed 14.4 MiB so far)\n",
      "24/12/03 15:45:29 WARN BlockManager: Persisting block rdd_107_25 to disk instead.\n",
      "24/12/03 15:45:45 WARN MemoryStore: Not enough space to cache rdd_107_26 in memory! (computed 27.6 MiB so far)\n",
      "24/12/03 15:45:45 WARN BlockManager: Persisting block rdd_107_26 to disk instead.\n",
      "24/12/03 15:45:54 WARN MemoryStore: Not enough space to cache rdd_107_24 in memory! (computed 28.3 MiB so far)\n",
      "24/12/03 15:46:16 WARN MemoryStore: Not enough space to cache rdd_107_28 in memory! (computed 20.1 MiB so far)\n",
      "24/12/03 15:46:16 WARN BlockManager: Persisting block rdd_107_28 to disk instead.\n",
      "24/12/03 15:46:21 WARN MemoryStore: Not enough space to cache rdd_107_25 in memory! (computed 14.4 MiB so far)\n",
      "24/12/03 15:46:21 WARN MemoryStore: Not enough space to cache rdd_107_26 in memory! (computed 14.7 MiB so far)\n",
      "24/12/03 15:46:23 WARN MemoryStore: Not enough space to cache rdd_107_27 in memory! (computed 12.9 MiB so far)\n",
      "24/12/03 15:46:29 WARN MemoryStore: Not enough space to cache rdd_107_30 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:46:29 WARN BlockManager: Persisting block rdd_107_30 to disk instead.\n",
      "24/12/03 15:46:31 WARN MemoryStore: Not enough space to cache rdd_107_31 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:46:31 WARN BlockManager: Persisting block rdd_107_31 to disk instead.\n",
      "24/12/03 15:46:37 WARN MemoryStore: Not enough space to cache rdd_107_29 in memory! (computed 13.0 MiB so far)\n",
      "24/12/03 15:46:37 WARN BlockManager: Persisting block rdd_107_29 to disk instead.\n",
      "24/12/03 15:47:03 WARN MemoryStore: Not enough space to cache rdd_107_28 in memory! (computed 20.1 MiB so far)\n",
      "24/12/03 15:47:30 WARN MemoryStore: Not enough space to cache rdd_107_29 in memory! (computed 6.7 MiB so far)\n",
      "24/12/03 15:47:31 WARN MemoryStore: Not enough space to cache rdd_107_30 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:47:32 WARN MemoryStore: Not enough space to cache rdd_107_31 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:47:33 WARN MemoryStore: Not enough space to cache rdd_107_32 in memory! (computed 25.4 MiB so far)\n",
      "24/12/03 15:47:33 WARN BlockManager: Persisting block rdd_107_32 to disk instead.\n",
      "24/12/03 15:47:39 WARN MemoryStore: Not enough space to cache rdd_107_35 in memory! (computed 6.8 MiB so far)\n",
      "24/12/03 15:47:39 WARN BlockManager: Persisting block rdd_107_35 to disk instead.\n",
      "24/12/03 15:47:44 WARN MemoryStore: Not enough space to cache rdd_107_33 in memory! (computed 12.4 MiB so far)\n",
      "24/12/03 15:47:44 WARN BlockManager: Persisting block rdd_107_33 to disk instead.\n",
      "24/12/03 15:48:00 WARN MemoryStore: Not enough space to cache rdd_107_34 in memory! (computed 24.4 MiB so far)\n",
      "24/12/03 15:48:00 WARN BlockManager: Persisting block rdd_107_34 to disk instead.\n",
      "24/12/03 15:48:08 WARN MemoryStore: Not enough space to cache rdd_107_32 in memory! (computed 25.4 MiB so far)\n",
      "24/12/03 15:48:24 WARN MemoryStore: Not enough space to cache rdd_107_36 in memory! (computed 13.1 MiB so far)\n",
      "24/12/03 15:48:24 WARN BlockManager: Persisting block rdd_107_36 to disk instead.\n",
      "24/12/03 15:48:35 WARN MemoryStore: Not enough space to cache rdd_107_33 in memory! (computed 24.7 MiB so far)\n",
      "24/12/03 15:48:37 WARN MemoryStore: Not enough space to cache rdd_107_34 in memory! (computed 12.4 MiB so far)\n",
      "24/12/03 15:48:38 WARN MemoryStore: Not enough space to cache rdd_107_35 in memory! (computed 13.1 MiB so far)\n",
      "24/12/03 15:48:44 WARN MemoryStore: Not enough space to cache rdd_107_38 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:48:44 WARN BlockManager: Persisting block rdd_107_38 to disk instead.\n",
      "24/12/03 15:48:45 WARN MemoryStore: Not enough space to cache rdd_107_39 in memory! (computed 7.1 MiB so far)\n",
      "24/12/03 15:48:45 WARN BlockManager: Persisting block rdd_107_39 to disk instead.\n",
      "24/12/03 15:48:50 WARN MemoryStore: Not enough space to cache rdd_107_37 in memory! (computed 13.6 MiB so far)\n",
      "24/12/03 15:48:50 WARN BlockManager: Persisting block rdd_107_37 to disk instead.\n",
      "24/12/03 15:49:14 WARN MemoryStore: Not enough space to cache rdd_107_36 in memory! (computed 13.1 MiB so far)\n",
      "24/12/03 15:49:40 WARN MemoryStore: Not enough space to cache rdd_107_37 in memory! (computed 6.7 MiB so far)\n",
      "24/12/03 15:49:42 WARN MemoryStore: Not enough space to cache rdd_107_38 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:49:44 WARN MemoryStore: Not enough space to cache rdd_107_39 in memory! (computed 7.1 MiB so far)\n",
      "24/12/03 15:49:44 WARN MemoryStore: Not enough space to cache rdd_107_40 in memory! (computed 25.1 MiB so far)\n",
      "24/12/03 15:49:44 WARN BlockManager: Persisting block rdd_107_40 to disk instead.\n",
      "24/12/03 15:49:51 WARN MemoryStore: Not enough space to cache rdd_107_43 in memory! (computed 7.0 MiB so far)\n",
      "24/12/03 15:49:51 WARN BlockManager: Persisting block rdd_107_43 to disk instead.\n",
      "24/12/03 15:49:55 WARN MemoryStore: Not enough space to cache rdd_107_41 in memory! (computed 12.4 MiB so far)\n",
      "24/12/03 15:49:55 WARN BlockManager: Persisting block rdd_107_41 to disk instead.\n",
      "24/12/03 15:50:11 WARN MemoryStore: Not enough space to cache rdd_107_42 in memory! (computed 24.4 MiB so far)\n",
      "24/12/03 15:50:11 WARN BlockManager: Persisting block rdd_107_42 to disk instead.\n",
      "24/12/03 15:50:19 WARN MemoryStore: Not enough space to cache rdd_107_40 in memory! (computed 25.1 MiB so far)\n",
      "24/12/03 15:50:45 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_107_41 in memory.\n",
      "24/12/03 15:50:45 WARN MemoryStore: Not enough space to cache rdd_107_41 in memory! (computed 384.0 B so far)\n",
      "24/12/03 15:50:45 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_107_45 in memory.\n",
      "24/12/03 15:50:45 WARN MemoryStore: Not enough space to cache rdd_107_45 in memory! (computed 384.0 B so far)\n",
      "24/12/03 15:50:45 WARN BlockManager: Persisting block rdd_107_45 to disk instead.\n",
      "24/12/03 15:50:46 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_107_42 in memory.\n",
      "24/12/03 15:50:46 WARN MemoryStore: Not enough space to cache rdd_107_42 in memory! (computed 384.0 B so far)\n",
      "24/12/03 15:50:48 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_107_43 in memory.\n",
      "24/12/03 15:50:48 WARN MemoryStore: Not enough space to cache rdd_107_43 in memory! (computed 384.0 B so far)\n",
      "24/12/03 15:50:49 WARN MemoryStore: Not enough space to cache rdd_107_44 in memory! (computed 25.5 MiB so far)\n",
      "24/12/03 15:50:49 WARN BlockManager: Persisting block rdd_107_44 to disk instead.\n",
      "24/12/03 15:51:05 WARN MemoryStore: Not enough space to cache rdd_107_44 in memory! (computed 6.6 MiB so far)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+\n",
      "|Timestamp       |From_Bank|From_Account|To_Bank|To_Account|Amount_Received|Receiving_Currency|Amount_Paid|Payment_Currency|Payment_Format|Pattern_Type|isLaundering|\n",
      "+----------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+\n",
      "|2022/09/01 00:17|020      |800104D70   |020    |800104D70 |6794.63        |US Dollar         |6794.63    |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "|2022/09/01 00:02|03196    |800107150   |03196  |800107150 |7739.29        |US Dollar         |7739.29    |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "|2022/09/01 00:17|01208    |80010E430   |01208  |80010E430 |1880.23        |US Dollar         |1880.23    |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "|2022/09/01 00:03|01208    |80010E650   |020    |80010E6F0 |7.396688E7     |US Dollar         |7.396688E7 |US Dollar       |Cheque        |NULL        |0           |\n",
      "|2022/09/01 00:02|01208    |80010E650   |020    |80010EA30 |4.5868456E7    |US Dollar         |4.5868456E7|US Dollar       |Cheque        |NULL        |0           |\n",
      "|2022/09/01 00:27|03203    |80010EA80   |03203  |80010EA80 |13284.41       |US Dollar         |13284.41   |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "|2022/09/01 00:25|020      |800104D20   |020    |800104D20 |9.72           |US Dollar         |9.72       |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "|2022/09/01 00:09|01208    |80010E430   |01208  |80010E430 |7.66           |US Dollar         |7.66       |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "|2022/09/01 00:09|011      |80010E600   |011    |80010E600 |16.33          |US Dollar         |16.33      |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "|2022/09/01 00:06|01208    |80010E650   |01208  |80010E650 |4.86           |US Dollar         |4.86       |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "|2022/09/01 00:25|020      |80010E6F0   |0183112|84DCA3150 |3.24           |US Dollar         |3.24       |US Dollar       |Credit Card   |NULL        |0           |\n",
      "|2022/09/01 00:16|020      |80010EA30   |01601  |802B6D220 |47.17          |US Dollar         |47.17      |US Dollar       |Credit Card   |NULL        |0           |\n",
      "|2022/09/01 00:14|020      |800073020   |020    |800073020 |848368.75      |US Dollar         |848368.75  |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "|2022/09/01 00:05|03566    |800345920   |03566  |800345920 |10134.05       |US Dollar         |10134.05   |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "|2022/09/01 00:09|011      |800329930   |02776  |800816450 |335999.7       |US Dollar         |335999.7   |US Dollar       |Cheque        |NULL        |0           |\n",
      "|2022/09/01 00:07|000      |8009B22F0   |000    |8009B22F0 |121.98         |US Dollar         |121.98     |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "|2022/09/01 00:24|011      |8003289F0   |0249457|825F4B630 |45.39          |US Dollar         |45.39      |US Dollar       |Credit Card   |NULL        |0           |\n",
      "|2022/09/01 00:22|000      |800815DE0   |000    |800815DE0 |23.4           |US Dollar         |23.4       |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "|2022/09/01 00:28|02776    |800816450   |0071901|81AB268F0 |30.23          |US Dollar         |30.23      |US Dollar       |Credit Card   |NULL        |0           |\n",
      "|2022/09/01 00:21|011081   |8008DDDF0   |011081 |8008DDDF0 |7.37           |US Dollar         |7.37       |US Dollar       |Reinvestment  |NULL        |0           |\n",
      "+----------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Cache the joined DataFrame\n",
    "joined_df.cache()\n",
    "\n",
    "# Display the cached DataFrame (use .show() instead of .display())\n",
    "joined_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:51:06.041886Z",
     "iopub.status.busy": "2024-12-03T15:51:06.040331Z",
     "iopub.status.idle": "2024-12-03T15:51:06.113729Z",
     "shell.execute_reply": "2024-12-03T15:51:06.110520Z",
     "shell.execute_reply.started": "2024-12-03T15:51:06.041816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Timestamp: string (nullable = true)\n",
      " |-- From_Bank: string (nullable = true)\n",
      " |-- From_Account: string (nullable = true)\n",
      " |-- To_Bank: string (nullable = true)\n",
      " |-- To_Account: string (nullable = true)\n",
      " |-- Amount_Received: float (nullable = true)\n",
      " |-- Receiving_Currency: string (nullable = true)\n",
      " |-- Amount_Paid: float (nullable = true)\n",
      " |-- Payment_Currency: string (nullable = true)\n",
      " |-- Payment_Format: string (nullable = true)\n",
      " |-- Pattern_Type: string (nullable = true)\n",
      " |-- isLaundering: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert 'isLaundering' from string to integer\n",
    "joined_df = joined_df.withColumn(\"isLaundering\", col(\"isLaundering\").cast(\"integer\"))\n",
    "\n",
    "\n",
    "# Verify the schema change\n",
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:51:06.116887Z",
     "iopub.status.busy": "2024-12-03T15:51:06.116159Z",
     "iopub.status.idle": "2024-12-03T15:51:16.459000Z",
     "shell.execute_reply": "2024-12-03T15:51:16.454366Z",
     "shell.execute_reply.started": "2024-12-03T15:51:06.116648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:51:07 WARN MemoryStore: Not enough space to cache rdd_107_5 in memory! (computed 26.2 MiB so far)\n",
      "24/12/03 15:51:07 WARN MemoryStore: Not enough space to cache rdd_107_4 in memory! (computed 44.3 MiB so far)\n",
      "24/12/03 15:51:08 WARN MemoryStore: Not enough space to cache rdd_107_10 in memory! (computed 12.4 MiB so far)\n",
      "24/12/03 15:51:08 WARN MemoryStore: Not enough space to cache rdd_107_11 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:51:08 WARN MemoryStore: Not enough space to cache rdd_107_9 in memory! (computed 49.5 MiB so far)\n",
      "24/12/03 15:51:09 WARN MemoryStore: Not enough space to cache rdd_107_12 in memory! (computed 26.7 MiB so far)\n",
      "24/12/03 15:51:09 WARN MemoryStore: Not enough space to cache rdd_107_14 in memory! (computed 26.0 MiB so far)\n",
      "24/12/03 15:51:09 WARN MemoryStore: Not enough space to cache rdd_107_13 in memory! (computed 45.1 MiB so far)\n",
      "24/12/03 15:51:10 WARN MemoryStore: Not enough space to cache rdd_107_17 in memory! (computed 24.4 MiB so far)\n",
      "24/12/03 15:51:10 WARN MemoryStore: Not enough space to cache rdd_107_18 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:51:10 WARN MemoryStore: Not enough space to cache rdd_107_21 in memory! (computed 12.9 MiB so far)\n",
      "24/12/03 15:51:11 WARN MemoryStore: Not enough space to cache rdd_107_23 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:51:11 WARN MemoryStore: Not enough space to cache rdd_107_25 in memory! (computed 7.5 MiB so far)\n",
      "24/12/03 15:51:11 WARN MemoryStore: Not enough space to cache rdd_107_24 in memory! (computed 7.5 MiB so far)\n",
      "24/12/03 15:51:11 WARN MemoryStore: Not enough space to cache rdd_107_26 in memory! (computed 7.4 MiB so far)\n",
      "24/12/03 15:51:12 WARN MemoryStore: Not enough space to cache rdd_107_27 in memory! (computed 6.7 MiB so far)\n",
      "24/12/03 15:51:12 WARN MemoryStore: Not enough space to cache rdd_107_28 in memory! (computed 6.6 MiB so far)\n",
      "24/12/03 15:51:12 WARN MemoryStore: Not enough space to cache rdd_107_29 in memory! (computed 13.0 MiB so far)\n",
      "24/12/03 15:51:13 WARN MemoryStore: Not enough space to cache rdd_107_32 in memory! (computed 13.3 MiB so far)\n",
      "24/12/03 15:51:13 WARN MemoryStore: Not enough space to cache rdd_107_31 in memory! (computed 24.4 MiB so far)\n",
      "24/12/03 15:51:14 WARN MemoryStore: Not enough space to cache rdd_107_34 in memory! (computed 12.4 MiB so far)\n",
      "24/12/03 15:51:14 WARN MemoryStore: Not enough space to cache rdd_107_35 in memory! (computed 6.8 MiB so far)\n",
      "24/12/03 15:51:14 WARN MemoryStore: Not enough space to cache rdd_107_37 in memory! (computed 6.7 MiB so far)\n",
      "24/12/03 15:51:14 WARN MemoryStore: Not enough space to cache rdd_107_39 in memory! (computed 7.1 MiB so far)\n",
      "24/12/03 15:51:14 WARN MemoryStore: Not enough space to cache rdd_107_38 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:51:14 WARN MemoryStore: Not enough space to cache rdd_107_40 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:51:15 WARN MemoryStore: Not enough space to cache rdd_107_41 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:51:15 WARN MemoryStore: Not enough space to cache rdd_107_42 in memory! (computed 6.4 MiB so far)\n",
      "24/12/03 15:51:15 WARN MemoryStore: Not enough space to cache rdd_107_43 in memory! (computed 7.0 MiB so far)\n",
      "24/12/03 15:51:15 WARN MemoryStore: Not enough space to cache rdd_107_44 in memory! (computed 6.6 MiB so far)\n",
      "24/12/03 15:51:15 WARN MemoryStore: Not enough space to cache rdd_107_45 in memory! (computed 6.7 MiB so far)\n",
      "[Stage 31:======================================================> (45 + 1) / 46]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|isLaundering|   count|\n",
      "+------------+--------+\n",
      "|           1|   84928|\n",
      "|           0|63065007|\n",
      "+------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "joined_df.groupBy(\"isLaundering\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:51:16.464029Z",
     "iopub.status.busy": "2024-12-03T15:51:16.462034Z",
     "iopub.status.idle": "2024-12-03T15:51:16.666223Z",
     "shell.execute_reply": "2024-12-03T15:51:16.664993Z",
     "shell.execute_reply.started": "2024-12-03T15:51:16.463955Z"
    }
   },
   "outputs": [],
   "source": [
    "# Register joined_df as a temporary view to use SQL\n",
    "joined_df.createOrReplaceTempView(\"joined_table\")\n",
    "\n",
    "# Step 1: Identify rows to drop\n",
    "# Here we assign a random value to each row that meets the condition, then select 50% of those rows\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM joined_table\n",
    "WHERE NOT ((Pattern_Type IS NULL) AND (isLaundering = 0) AND (rand() < 0.5))\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "balanced_df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:51:16.677371Z",
     "iopub.status.busy": "2024-12-03T15:51:16.676286Z",
     "iopub.status.idle": "2024-12-03T15:51:16.695999Z",
     "shell.execute_reply": "2024-12-03T15:51:16.694510Z",
     "shell.execute_reply.started": "2024-12-03T15:51:16.677302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Timestamp: string, From_Bank: string, From_Account: string, To_Bank: string, To_Account: string, Amount_Received: float, Receiving_Currency: string, Amount_Paid: float, Payment_Currency: string, Payment_Format: string, Pattern_Type: string, isLaundering: int]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:51:16.698212Z",
     "iopub.status.busy": "2024-12-03T15:51:16.697720Z",
     "iopub.status.idle": "2024-12-03T15:53:17.444801Z",
     "shell.execute_reply": "2024-12-03T15:53:17.440558Z",
     "shell.execute_reply.started": "2024-12-03T15:51:16.698148Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:51:17 WARN MemoryStore: Not enough space to cache rdd_107_2 in memory! (computed 14.3 MiB so far)\n",
      "24/12/03 15:51:17 WARN MemoryStore: Not enough space to cache rdd_107_1 in memory! (computed 7.5 MiB so far)\n",
      "24/12/03 15:51:17 WARN MemoryStore: Not enough space to cache rdd_107_3 in memory! (computed 7.4 MiB so far)\n",
      "24/12/03 15:51:17 WARN MemoryStore: Not enough space to cache rdd_107_0 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:51:40 WARN MemoryStore: Not enough space to cache rdd_107_11 in memory! (computed 42.5 MiB so far)\n",
      "24/12/03 15:51:50 WARN MemoryStore: Not enough space to cache rdd_107_13 in memory! (computed 45.1 MiB so far)\n",
      "24/12/03 15:51:51 WARN MemoryStore: Not enough space to cache rdd_107_15 in memory! (computed 43.5 MiB so far)\n",
      "24/12/03 15:52:26 WARN MemoryStore: Not enough space to cache rdd_107_28 in memory! (computed 51.9 MiB so far)\n",
      "24/12/03 15:52:40 WARN MemoryStore: Not enough space to cache rdd_107_34 in memory! (computed 42.4 MiB so far)\n",
      "24/12/03 15:52:40 WARN MemoryStore: Not enough space to cache rdd_107_35 in memory! (computed 45.0 MiB so far)\n",
      "24/12/03 15:52:58 WARN MemoryStore: Not enough space to cache rdd_107_41 in memory! (computed 43.1 MiB so far)\n",
      "24/12/03 15:53:00 WARN MemoryStore: Not enough space to cache rdd_107_43 in memory! (computed 45.1 MiB so far)\n",
      "24/12/03 15:53:13 WARN MemoryStore: Not enough space to cache rdd_126_5 in memory! (computed 31.1 MiB so far)\n",
      "24/12/03 15:53:14 WARN MemoryStore: Not enough space to cache rdd_126_11 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:53:14 WARN MemoryStore: Not enough space to cache rdd_126_8 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:53:14 WARN MemoryStore: Not enough space to cache rdd_126_10 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:53:14 WARN MemoryStore: Not enough space to cache rdd_126_12 in memory! (computed 31.9 MiB so far)\n",
      "24/12/03 15:53:14 WARN MemoryStore: Not enough space to cache rdd_126_13 in memory! (computed 32.0 MiB so far)\n",
      "24/12/03 15:53:14 WARN MemoryStore: Not enough space to cache rdd_126_14 in memory! (computed 8.2 MiB so far)\n",
      "24/12/03 15:53:14 WARN MemoryStore: Not enough space to cache rdd_126_16 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:53:15 WARN MemoryStore: Not enough space to cache rdd_126_19 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:53:15 WARN MemoryStore: Not enough space to cache rdd_126_18 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:53:15 WARN MemoryStore: Not enough space to cache rdd_126_21 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:53:15 WARN MemoryStore: Not enough space to cache rdd_126_23 in memory! (computed 31.0 MiB so far)\n",
      "24/12/03 15:53:15 WARN MemoryStore: Not enough space to cache rdd_126_25 in memory! (computed 8.4 MiB so far)\n",
      "24/12/03 15:53:15 WARN MemoryStore: Not enough space to cache rdd_126_24 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:53:15 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_126_30 in memory.\n",
      "24/12/03 15:53:15 WARN MemoryStore: Not enough space to cache rdd_126_30 in memory! (computed 384.0 B so far)\n",
      "24/12/03 15:53:15 WARN MemoryStore: Not enough space to cache rdd_126_27 in memory! (computed 30.3 MiB so far)\n",
      "24/12/03 15:53:16 WARN MemoryStore: Not enough space to cache rdd_126_28 in memory! (computed 31.1 MiB so far)\n",
      "24/12/03 15:53:16 WARN MemoryStore: Not enough space to cache rdd_126_29 in memory! (computed 15.9 MiB so far)\n",
      "24/12/03 15:53:16 WARN MemoryStore: Not enough space to cache rdd_126_32 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:53:16 WARN MemoryStore: Not enough space to cache rdd_126_33 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:53:16 WARN MemoryStore: Not enough space to cache rdd_126_37 in memory! (computed 8.2 MiB so far)\n",
      "24/12/03 15:53:16 WARN MemoryStore: Not enough space to cache rdd_126_36 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:53:16 WARN MemoryStore: Not enough space to cache rdd_126_35 in memory! (computed 31.9 MiB so far)\n",
      "24/12/03 15:53:16 WARN MemoryStore: Not enough space to cache rdd_126_41 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:53:16 WARN MemoryStore: Not enough space to cache rdd_126_39 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:53:16 WARN MemoryStore: Not enough space to cache rdd_126_40 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:53:16 WARN MemoryStore: Not enough space to cache rdd_126_42 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:53:17 WARN MemoryStore: Not enough space to cache rdd_126_43 in memory! (computed 30.4 MiB so far)\n",
      "[Stage 35:======================================================> (45 + 1) / 46]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|isLaundering|   count|\n",
      "+------------+--------+\n",
      "|           1|   84928|\n",
      "|           0|31540149|\n",
      "+------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "balanced_df.cache().groupBy(\"isLaundering\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:53:17.451118Z",
     "iopub.status.busy": "2024-12-03T15:53:17.450467Z",
     "iopub.status.idle": "2024-12-03T15:53:31.019525Z",
     "shell.execute_reply": "2024-12-03T15:53:31.017424Z",
     "shell.execute_reply.started": "2024-12-03T15:53:17.451009Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:53:17 WARN MemoryStore: Not enough space to cache rdd_126_2 in memory! (computed 8.4 MiB so far)\n",
      "24/12/03 15:53:17 WARN MemoryStore: Not enough space to cache rdd_126_3 in memory! (computed 16.0 MiB so far)\n",
      "24/12/03 15:53:17 WARN MemoryStore: Not enough space to cache rdd_126_1 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:53:17 WARN MemoryStore: Not enough space to cache rdd_126_0 in memory! (computed 15.9 MiB so far)\n",
      "24/12/03 15:53:19 WARN MemoryStore: Not enough space to cache rdd_126_4 in memory! (computed 30.5 MiB so far)\n",
      "24/12/03 15:53:20 WARN MemoryStore: Not enough space to cache rdd_126_5 in memory! (computed 15.7 MiB so far)\n",
      "24/12/03 15:53:21 WARN MemoryStore: Not enough space to cache rdd_126_8 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:53:21 WARN MemoryStore: Not enough space to cache rdd_126_11 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:53:21 WARN MemoryStore: Not enough space to cache rdd_126_10 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:53:21 WARN MemoryStore: Not enough space to cache rdd_126_12 in memory! (computed 31.9 MiB so far)\n",
      "24/12/03 15:53:22 WARN MemoryStore: Not enough space to cache rdd_126_13 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:53:22 WARN MemoryStore: Not enough space to cache rdd_126_14 in memory! (computed 8.2 MiB so far)\n",
      "24/12/03 15:53:23 WARN MemoryStore: Not enough space to cache rdd_126_16 in memory! (computed 30.4 MiB so far)\n",
      "24/12/03 15:53:23 WARN MemoryStore: Not enough space to cache rdd_126_18 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:53:23 WARN MemoryStore: Not enough space to cache rdd_126_19 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:53:24 WARN MemoryStore: Not enough space to cache rdd_126_21 in memory! (computed 30.5 MiB so far)\n",
      "24/12/03 15:53:24 WARN MemoryStore: Not enough space to cache rdd_126_23 in memory! (computed 15.9 MiB so far)\n",
      "24/12/03 15:53:24 WARN MemoryStore: Not enough space to cache rdd_126_24 in memory! (computed 8.4 MiB so far)\n",
      "24/12/03 15:53:25 WARN MemoryStore: Not enough space to cache rdd_126_25 in memory! (computed 32.0 MiB so far)\n",
      "24/12/03 15:53:25 WARN MemoryStore: Not enough space to cache rdd_126_27 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:53:25 WARN MemoryStore: Not enough space to cache rdd_126_28 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:53:26 WARN MemoryStore: Not enough space to cache rdd_126_30 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:53:26 WARN MemoryStore: Not enough space to cache rdd_126_29 in memory! (computed 30.8 MiB so far)\n",
      "24/12/03 15:53:27 WARN MemoryStore: Not enough space to cache rdd_126_32 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:53:27 WARN MemoryStore: Not enough space to cache rdd_126_33 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:53:28 WARN MemoryStore: Not enough space to cache rdd_126_35 in memory! (computed 16.1 MiB so far)\n",
      "24/12/03 15:53:28 WARN MemoryStore: Not enough space to cache rdd_126_36 in memory! (computed 8.4 MiB so far)\n",
      "24/12/03 15:53:28 WARN MemoryStore: Not enough space to cache rdd_126_37 in memory! (computed 31.2 MiB so far)\n",
      "24/12/03 15:53:28 WARN MemoryStore: Not enough space to cache rdd_126_39 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:53:29 WARN MemoryStore: Not enough space to cache rdd_126_40 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:53:29 WARN MemoryStore: Not enough space to cache rdd_126_41 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:53:29 WARN MemoryStore: Not enough space to cache rdd_126_42 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:53:30 WARN MemoryStore: Not enough space to cache rdd_126_43 in memory! (computed 15.5 MiB so far)\n",
      "[Stage 38:======================================================> (45 + 1) / 46]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+\n",
      "|Timestamp|From_Bank|From_Account|To_Bank|To_Account|Amount_Received|Receiving_Currency|Amount_Paid|Payment_Currency|Payment_Format|Pattern_Type|isLaundering|\n",
      "+---------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+\n",
      "|        0|        0|           0|      0|         0|              0|                 0|          0|               0|             0|    31540149|           0|\n",
      "+---------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count NULL values in each column\n",
    "null_counts = balanced_df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in balanced_df.columns])\n",
    "\n",
    "# Show the result\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:53:31.022787Z",
     "iopub.status.busy": "2024-12-03T15:53:31.021554Z",
     "iopub.status.idle": "2024-12-03T15:53:31.065580Z",
     "shell.execute_reply": "2024-12-03T15:53:31.063813Z",
     "shell.execute_reply.started": "2024-12-03T15:53:31.022699Z"
    }
   },
   "outputs": [],
   "source": [
    "balanced_df = balanced_df.na.fill({\n",
    "    \"Pattern_Type\": \"Unknown\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:53:31.068217Z",
     "iopub.status.busy": "2024-12-03T15:53:31.067654Z",
     "iopub.status.idle": "2024-12-03T15:53:31.336926Z",
     "shell.execute_reply": "2024-12-03T15:53:31.335450Z",
     "shell.execute_reply.started": "2024-12-03T15:53:31.068163Z"
    }
   },
   "outputs": [],
   "source": [
    "balanced_df = balanced_df.withColumn(\"Timestamp\", to_timestamp(\"Timestamp\", \"yyyy/MM/dd HH:mm\")) \\\n",
    "                         .withColumn(\"Hour\", hour(\"Timestamp\")) \\\n",
    "                         .withColumn(\"DayOfWeek\", dayofweek(\"Timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:53:31.343416Z",
     "iopub.status.busy": "2024-12-03T15:53:31.342644Z",
     "iopub.status.idle": "2024-12-03T15:53:31.754489Z",
     "shell.execute_reply": "2024-12-03T15:53:31.753155Z",
     "shell.execute_reply.started": "2024-12-03T15:53:31.343349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+----+---------+\n",
      "|Timestamp          |From_Bank|From_Account|To_Bank|To_Account|Amount_Received|Receiving_Currency|Amount_Paid|Payment_Currency|Payment_Format|Pattern_Type|isLaundering|Hour|DayOfWeek|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+----+---------+\n",
      "|2022-09-01 00:17:00|020      |800104D70   |020    |800104D70 |6794.63        |US Dollar         |6794.63    |US Dollar       |Reinvestment  |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:02:00|03196    |800107150   |03196  |800107150 |7739.29        |US Dollar         |7739.29    |US Dollar       |Reinvestment  |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:17:00|01208    |80010E430   |01208  |80010E430 |1880.23        |US Dollar         |1880.23    |US Dollar       |Reinvestment  |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:03:00|01208    |80010E650   |020    |80010E6F0 |7.396688E7     |US Dollar         |7.396688E7 |US Dollar       |Cheque        |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:27:00|03203    |80010EA80   |03203  |80010EA80 |13284.41       |US Dollar         |13284.41   |US Dollar       |Reinvestment  |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:09:00|01208    |80010E430   |01208  |80010E430 |7.66           |US Dollar         |7.66       |US Dollar       |Reinvestment  |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:16:00|020      |80010EA30   |01601  |802B6D220 |47.17          |US Dollar         |47.17      |US Dollar       |Credit Card   |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:14:00|020      |800073020   |020    |800073020 |848368.75      |US Dollar         |848368.75  |US Dollar       |Reinvestment  |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:05:00|03566    |800345920   |03566  |800345920 |10134.05       |US Dollar         |10134.05   |US Dollar       |Reinvestment  |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:09:00|011      |800329930   |02776  |800816450 |335999.7       |US Dollar         |335999.7   |US Dollar       |Cheque        |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:22:00|000      |800815DE0   |000    |800815DE0 |23.4           |US Dollar         |23.4       |US Dollar       |Reinvestment  |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:28:00|02776    |800816450   |0071901|81AB268F0 |30.23          |US Dollar         |30.23      |US Dollar       |Credit Card   |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:21:00|011081   |8008DDDF0   |011081 |8008DDDF0 |7.37           |US Dollar         |7.37       |US Dollar       |Reinvestment  |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:15:00|01601    |800970C80   |0260376|825F955A0 |121.38         |US Dollar         |121.38     |US Dollar       |Credit Card   |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:13:00|021418   |800A37E30   |001315 |8009BDC30 |178265.0       |US Dollar         |178265.0   |US Dollar       |Cheque        |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:12:00|00741    |800A37DE0   |00741  |800A37DE0 |4968.24        |US Dollar         |4968.24    |US Dollar       |Reinvestment  |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:20:00|001315   |8009BDC30   |0125106|816DF5400 |165.63         |US Dollar         |165.63     |US Dollar       |Credit Card   |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:00:00|001046   |800A37D90   |0274159|820C04F20 |26.42          |US Dollar         |26.42      |US Dollar       |Credit Card   |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:09:00|01601    |800A38370   |021418 |808FC8680 |0.09           |US Dollar         |0.09       |US Dollar       |Credit Card   |Unknown     |0           |0   |5        |\n",
      "|2022-09-01 00:14:00|000      |800A39060   |02310  |800A39B80 |4332.0         |US Dollar         |4332.0     |US Dollar       |Cheque        |Unknown     |0           |0   |5        |\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:53:31 WARN MemoryStore: Not enough space to cache rdd_126_0 in memory! (computed 31.0 MiB so far)\n"
     ]
    }
   ],
   "source": [
    "# Show the final DataFrame\n",
    "balanced_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Engineering**\n",
    "Calculate FanOut, FanIn, and AvgAmountSent.\n",
    "\n",
    "-FanOut:\n",
    "how many different transactions it initiates.\n",
    "\n",
    "-FanIn:\n",
    "how many different transactions it receives.\n",
    "\n",
    "-AvgAmountSent:\n",
    "the typical transaction size for each account as a sender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:53:31.756600Z",
     "iopub.status.busy": "2024-12-03T15:53:31.756111Z",
     "iopub.status.idle": "2024-12-03T15:53:31.858501Z",
     "shell.execute_reply": "2024-12-03T15:53:31.856892Z",
     "shell.execute_reply.started": "2024-12-03T15:53:31.756547Z"
    }
   },
   "outputs": [],
   "source": [
    "# Window specifications\n",
    "sender_window = Window.partitionBy(\"From_Account\")\n",
    "receiver_window = Window.partitionBy(\"To_Account\")\n",
    "\n",
    "# Calculate fan-out, fan-in, and average amount sent\n",
    "featured_df = balanced_df.withColumn(\"FanOut\", count(\"To_Account\").over(sender_window)) \\\n",
    "                         .withColumn(\"FanIn\", count(\"From_Account\").over(receiver_window)) \\\n",
    "                         .withColumn(\"AvgAmountSent\", avg(\"Amount_Paid\").over(sender_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:53:31.863747Z",
     "iopub.status.busy": "2024-12-03T15:53:31.863241Z",
     "iopub.status.idle": "2024-12-03T15:56:16.980509Z",
     "shell.execute_reply": "2024-12-03T15:56:16.978978Z",
     "shell.execute_reply.started": "2024-12-03T15:53:31.863698Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:53:32 WARN MemoryStore: Not enough space to cache rdd_126_3 in memory! (computed 8.4 MiB so far)\n",
      "24/12/03 15:53:32 WARN MemoryStore: Not enough space to cache rdd_126_1 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:53:32 WARN MemoryStore: Not enough space to cache rdd_126_0 in memory! (computed 15.9 MiB so far)\n",
      "24/12/03 15:53:32 WARN MemoryStore: Not enough space to cache rdd_126_2 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:53:38 WARN MemoryStore: Not enough space to cache rdd_126_4 in memory! (computed 30.5 MiB so far)\n",
      "24/12/03 15:53:38 WARN MemoryStore: Not enough space to cache rdd_126_5 in memory! (computed 15.7 MiB so far)\n",
      "24/12/03 15:53:42 WARN MemoryStore: Not enough space to cache rdd_126_8 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:53:42 WARN MemoryStore: Not enough space to cache rdd_126_10 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:53:42 WARN MemoryStore: Not enough space to cache rdd_126_11 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:53:47 WARN MemoryStore: Not enough space to cache rdd_126_12 in memory! (computed 31.9 MiB so far)\n",
      "24/12/03 15:53:47 WARN MemoryStore: Not enough space to cache rdd_126_13 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:53:47 WARN MemoryStore: Not enough space to cache rdd_126_14 in memory! (computed 8.2 MiB so far)\n",
      "24/12/03 15:53:51 WARN MemoryStore: Not enough space to cache rdd_126_16 in memory! (computed 30.4 MiB so far)\n",
      "24/12/03 15:53:52 WARN MemoryStore: Not enough space to cache rdd_126_18 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:53:52 WARN MemoryStore: Not enough space to cache rdd_126_19 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:53:57 WARN MemoryStore: Not enough space to cache rdd_126_21 in memory! (computed 30.5 MiB so far)\n",
      "24/12/03 15:53:57 WARN MemoryStore: Not enough space to cache rdd_126_23 in memory! (computed 15.9 MiB so far)\n",
      "24/12/03 15:54:00 WARN MemoryStore: Not enough space to cache rdd_126_24 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:54:01 WARN MemoryStore: Not enough space to cache rdd_126_25 in memory! (computed 8.4 MiB so far)\n",
      "24/12/03 15:54:02 WARN MemoryStore: Not enough space to cache rdd_126_27 in memory! (computed 30.3 MiB so far)\n",
      "24/12/03 15:54:04 WARN MemoryStore: Not enough space to cache rdd_126_28 in memory! (computed 15.7 MiB so far)\n",
      "24/12/03 15:54:05 WARN MemoryStore: Not enough space to cache rdd_126_29 in memory! (computed 8.2 MiB so far)\n",
      "24/12/03 15:54:06 WARN MemoryStore: Not enough space to cache rdd_126_30 in memory! (computed 30.3 MiB so far)\n",
      "24/12/03 15:54:09 WARN MemoryStore: Not enough space to cache rdd_126_32 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:54:10 WARN MemoryStore: Not enough space to cache rdd_126_33 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:54:11 WARN MemoryStore: Not enough space to cache rdd_126_35 in memory! (computed 8.3 MiB so far)\n",
      "24/12/03 15:54:14 WARN MemoryStore: Not enough space to cache rdd_126_36 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:54:15 WARN MemoryStore: Not enough space to cache rdd_126_37 in memory! (computed 31.2 MiB so far)\n",
      "24/12/03 15:54:16 WARN MemoryStore: Not enough space to cache rdd_126_39 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:54:19 WARN MemoryStore: Not enough space to cache rdd_126_40 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:54:20 WARN MemoryStore: Not enough space to cache rdd_126_41 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:54:20 WARN MemoryStore: Not enough space to cache rdd_126_42 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:54:21 WARN MemoryStore: Not enough space to cache rdd_126_43 in memory! (computed 15.5 MiB so far)\n",
      "[Stage 51:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+----+---------+------+-----+------------------+\n",
      "|Timestamp          |From_Bank|From_Account|To_Bank|To_Account|Amount_Received|Receiving_Currency|Amount_Paid|Payment_Currency|Payment_Format|Pattern_Type|isLaundering|Hour|DayOfWeek|FanOut|FanIn|AvgAmountSent     |\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+----+---------+------+-----+------------------+\n",
      "|2022-09-01 05:21:00|004      |800060A20   |004    |800060A20 |1834.72        |Rupee             |1834.72    |Rupee           |Reinvestment  |Unknown     |0           |5   |5        |228   |53   |157083.68798252573|\n",
      "|2022-09-08 07:24:00|004      |800060A20   |025    |8129D4D00 |922259.2       |Rupee             |922259.2   |Rupee           |ACH           |Unknown     |0           |7   |5        |228   |16   |157083.68798252573|\n",
      "|2022-09-01 05:55:00|004      |800060A20   |004    |800060A20 |21381.18       |Rupee             |21381.18   |Rupee           |Cheque        |Unknown     |0           |5   |5        |228   |53   |157083.68798252573|\n",
      "|2022-09-01 12:24:00|004      |800060A20   |025    |8129D4D00 |595031.7       |Rupee             |595031.7   |Rupee           |Cheque        |Unknown     |0           |12  |5        |228   |16   |157083.68798252573|\n",
      "|2022-09-09 01:49:00|004      |800060A20   |004    |800060A20 |10683.91       |Rupee             |10683.91   |Rupee           |Credit Card   |Unknown     |0           |1   |6        |228   |53   |157083.68798252573|\n",
      "|2022-09-09 22:58:00|004      |800060A20   |025    |8129D4D00 |595031.7       |Rupee             |595031.7   |Rupee           |Cheque        |Unknown     |0           |22  |6        |228   |16   |157083.68798252573|\n",
      "|2022-09-01 05:46:00|004      |800060A20   |004    |800060A20 |10683.91       |Rupee             |10683.91   |Rupee           |Credit Card   |Unknown     |0           |5   |5        |228   |53   |157083.68798252573|\n",
      "|2022-09-10 01:03:00|004      |800060A20   |025    |8129D4D00 |922259.2       |Rupee             |922259.2   |Rupee           |ACH           |Unknown     |0           |1   |7        |228   |16   |157083.68798252573|\n",
      "|2022-09-09 01:48:00|004      |800060A20   |004    |800060A20 |11860.6        |Rupee             |11860.6    |Rupee           |Wire          |Unknown     |0           |1   |6        |228   |53   |157083.68798252573|\n",
      "|2022-09-02 05:20:00|004      |800060A20   |025    |8129D4D00 |595031.7       |Rupee             |595031.7   |Rupee           |Cheque        |Unknown     |0           |5   |6        |228   |16   |157083.68798252573|\n",
      "|2022-09-01 05:53:00|004      |800060A20   |004    |800060A20 |11860.6        |Rupee             |11860.6    |Rupee           |Wire          |Unknown     |0           |5   |5        |228   |53   |157083.68798252573|\n",
      "|2022-09-02 05:01:00|004      |800060A20   |025    |8129D4D00 |922259.2       |Rupee             |922259.2   |Rupee           |ACH           |Unknown     |0           |5   |6        |228   |16   |157083.68798252573|\n",
      "|2022-09-02 07:16:00|004      |800060A20   |004    |800060A20 |10683.91       |Rupee             |10683.91   |Rupee           |Credit Card   |Unknown     |0           |7   |6        |228   |53   |157083.68798252573|\n",
      "|2022-09-12 10:27:00|004      |800060A20   |025    |8129D4D00 |595031.7       |Rupee             |595031.7   |Rupee           |Cheque        |Unknown     |0           |10  |2        |228   |16   |157083.68798252573|\n",
      "|2022-09-02 07:18:00|004      |800060A20   |004    |800060A20 |11860.6        |Rupee             |11860.6    |Rupee           |Wire          |Unknown     |0           |7   |6        |228   |53   |157083.68798252573|\n",
      "|2022-09-03 12:18:00|004      |800060A20   |025    |8129D4D00 |595031.7       |Rupee             |595031.7   |Rupee           |Cheque        |Unknown     |0           |12  |7        |228   |16   |157083.68798252573|\n",
      "|2022-09-12 12:46:00|004      |800060A20   |004    |800060A20 |21381.18       |Rupee             |21381.18   |Rupee           |Cheque        |Unknown     |0           |12  |2        |228   |53   |157083.68798252573|\n",
      "|2022-09-03 12:18:00|004      |800060A20   |025    |8129D4D00 |922259.2       |Rupee             |922259.2   |Rupee           |ACH           |Unknown     |0           |12  |7        |228   |16   |157083.68798252573|\n",
      "|2022-09-05 19:53:00|004      |800060A20   |004    |800060A20 |3117.27        |Euro              |268273.75  |Rupee           |ACH           |STACK       |1           |19  |2        |228   |53   |157083.68798252573|\n",
      "|2022-09-13 08:23:00|004      |800060A20   |025    |8129D4D00 |595031.7       |Rupee             |595031.7   |Rupee           |Cheque        |Unknown     |0           |8   |3        |228   |16   |157083.68798252573|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+----+---------+------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "balanced_df.unpersist()\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "featured_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Variables\n",
    "\n",
    "Converted categorical columns into numerical indices using StringIndexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:56:16.983305Z",
     "iopub.status.busy": "2024-12-03T15:56:16.982593Z",
     "iopub.status.idle": "2024-12-03T15:56:37.556473Z",
     "shell.execute_reply": "2024-12-03T15:56:37.555263Z",
     "shell.execute_reply.started": "2024-12-03T15:56:16.983070Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:56:18 WARN MemoryStore: Not enough space to cache rdd_126_5 in memory! (computed 31.1 MiB so far)\n",
      "24/12/03 15:56:18 WARN MemoryStore: Not enough space to cache rdd_126_6 in memory! (computed 31.0 MiB so far)\n",
      "24/12/03 15:56:19 WARN MemoryStore: Not enough space to cache rdd_126_7 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:56:19 WARN MemoryStore: Not enough space to cache rdd_126_8 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:56:19 WARN MemoryStore: Not enough space to cache rdd_126_10 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:56:19 WARN MemoryStore: Not enough space to cache rdd_126_11 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:56:20 WARN MemoryStore: Not enough space to cache rdd_126_13 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:56:20 WARN MemoryStore: Not enough space to cache rdd_126_14 in memory! (computed 8.2 MiB so far)\n",
      "24/12/03 15:56:20 WARN MemoryStore: Not enough space to cache rdd_126_12 in memory! (computed 31.9 MiB so far)\n",
      "24/12/03 15:56:20 WARN MemoryStore: Not enough space to cache rdd_126_15 in memory! (computed 8.1 MiB so far)\n",
      "24/12/03 15:56:20 WARN MemoryStore: Not enough space to cache rdd_126_17 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:56:20 WARN MemoryStore: Not enough space to cache rdd_126_18 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:56:20 WARN MemoryStore: Not enough space to cache rdd_126_16 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:56:20 WARN MemoryStore: Not enough space to cache rdd_126_19 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:56:21 WARN MemoryStore: Not enough space to cache rdd_126_20 in memory! (computed 30.5 MiB so far)\n",
      "24/12/03 15:56:21 WARN MemoryStore: Not enough space to cache rdd_126_21 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:56:21 WARN MemoryStore: Not enough space to cache rdd_126_23 in memory! (computed 8.1 MiB so far)\n",
      "24/12/03 15:56:21 WARN MemoryStore: Not enough space to cache rdd_126_24 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:56:22 WARN MemoryStore: Not enough space to cache rdd_126_25 in memory! (computed 32.0 MiB so far)\n",
      "24/12/03 15:56:22 WARN MemoryStore: Not enough space to cache rdd_126_27 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:56:22 WARN MemoryStore: Not enough space to cache rdd_126_28 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:56:22 WARN MemoryStore: Not enough space to cache rdd_126_30 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:56:22 WARN MemoryStore: Not enough space to cache rdd_126_29 in memory! (computed 30.8 MiB so far)\n",
      "24/12/03 15:56:22 WARN MemoryStore: Not enough space to cache rdd_126_32 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:56:23 WARN MemoryStore: Not enough space to cache rdd_126_33 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:56:23 WARN MemoryStore: Not enough space to cache rdd_126_35 in memory! (computed 16.1 MiB so far)\n",
      "24/12/03 15:56:23 WARN MemoryStore: Not enough space to cache rdd_126_36 in memory! (computed 8.4 MiB so far)\n",
      "24/12/03 15:56:23 WARN MemoryStore: Not enough space to cache rdd_126_37 in memory! (computed 31.2 MiB so far)\n",
      "24/12/03 15:56:23 WARN MemoryStore: Not enough space to cache rdd_126_39 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:56:23 WARN MemoryStore: Not enough space to cache rdd_126_40 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:56:24 WARN MemoryStore: Not enough space to cache rdd_126_41 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:56:24 WARN MemoryStore: Not enough space to cache rdd_126_42 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:56:24 WARN MemoryStore: Not enough space to cache rdd_126_43 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:56:25 WARN MemoryStore: Not enough space to cache rdd_126_5 in memory! (computed 15.7 MiB so far)\n",
      "24/12/03 15:56:25 WARN MemoryStore: Not enough space to cache rdd_126_6 in memory! (computed 15.9 MiB so far)\n",
      "24/12/03 15:56:25 WARN MemoryStore: Not enough space to cache rdd_126_7 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:56:26 WARN MemoryStore: Not enough space to cache rdd_126_10 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:56:26 WARN MemoryStore: Not enough space to cache rdd_126_11 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:56:26 WARN MemoryStore: Not enough space to cache rdd_126_8 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:56:26 WARN MemoryStore: Not enough space to cache rdd_126_12 in memory! (computed 31.9 MiB so far)\n",
      "24/12/03 15:56:26 WARN MemoryStore: Not enough space to cache rdd_126_14 in memory! (computed 8.2 MiB so far)\n",
      "24/12/03 15:56:26 WARN MemoryStore: Not enough space to cache rdd_126_13 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:56:26 WARN MemoryStore: Not enough space to cache rdd_126_15 in memory! (computed 8.1 MiB so far)\n",
      "24/12/03 15:56:27 WARN MemoryStore: Not enough space to cache rdd_126_16 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:56:27 WARN MemoryStore: Not enough space to cache rdd_126_18 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:56:27 WARN MemoryStore: Not enough space to cache rdd_126_17 in memory! (computed 30.3 MiB so far)\n",
      "24/12/03 15:56:27 WARN MemoryStore: Not enough space to cache rdd_126_19 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:56:27 WARN MemoryStore: Not enough space to cache rdd_126_21 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:56:27 WARN MemoryStore: Not enough space to cache rdd_126_20 in memory! (computed 30.5 MiB so far)\n",
      "24/12/03 15:56:27 WARN MemoryStore: Not enough space to cache rdd_126_23 in memory! (computed 8.1 MiB so far)\n",
      "24/12/03 15:56:28 WARN MemoryStore: Not enough space to cache rdd_126_24 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:56:28 WARN MemoryStore: Not enough space to cache rdd_126_25 in memory! (computed 32.0 MiB so far)\n",
      "24/12/03 15:56:28 WARN MemoryStore: Not enough space to cache rdd_126_27 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:56:28 WARN MemoryStore: Not enough space to cache rdd_126_28 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:56:28 WARN MemoryStore: Not enough space to cache rdd_126_30 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:56:28 WARN MemoryStore: Not enough space to cache rdd_126_29 in memory! (computed 30.8 MiB so far)\n",
      "24/12/03 15:56:28 WARN MemoryStore: Not enough space to cache rdd_126_32 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:56:29 WARN MemoryStore: Not enough space to cache rdd_126_35 in memory! (computed 16.1 MiB so far)\n",
      "24/12/03 15:56:29 WARN MemoryStore: Not enough space to cache rdd_126_33 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:56:29 WARN MemoryStore: Not enough space to cache rdd_126_36 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:56:29 WARN MemoryStore: Not enough space to cache rdd_126_39 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:56:29 WARN MemoryStore: Not enough space to cache rdd_126_37 in memory! (computed 31.2 MiB so far)\n",
      "24/12/03 15:56:29 WARN MemoryStore: Not enough space to cache rdd_126_40 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:56:30 WARN MemoryStore: Not enough space to cache rdd_126_41 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:56:30 WARN MemoryStore: Not enough space to cache rdd_126_42 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:56:30 WARN MemoryStore: Not enough space to cache rdd_126_43 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:56:31 WARN MemoryStore: Not enough space to cache rdd_126_7 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:56:31 WARN MemoryStore: Not enough space to cache rdd_126_6 in memory! (computed 15.9 MiB so far)\n",
      "24/12/03 15:56:31 WARN MemoryStore: Not enough space to cache rdd_126_5 in memory! (computed 31.1 MiB so far)\n",
      "24/12/03 15:56:32 WARN MemoryStore: Not enough space to cache rdd_126_8 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:56:32 WARN MemoryStore: Not enough space to cache rdd_126_11 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:56:32 WARN MemoryStore: Not enough space to cache rdd_126_10 in memory! (computed 30.4 MiB so far)\n",
      "24/12/03 15:56:32 WARN MemoryStore: Not enough space to cache rdd_126_13 in memory! (computed 8.4 MiB so far)\n",
      "24/12/03 15:56:32 WARN MemoryStore: Not enough space to cache rdd_126_12 in memory! (computed 16.1 MiB so far)\n",
      "24/12/03 15:56:33 WARN MemoryStore: Not enough space to cache rdd_126_15 in memory! (computed 8.1 MiB so far)\n",
      "24/12/03 15:56:33 WARN MemoryStore: Not enough space to cache rdd_126_14 in memory! (computed 31.4 MiB so far)\n",
      "24/12/03 15:56:33 WARN MemoryStore: Not enough space to cache rdd_126_17 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:56:33 WARN MemoryStore: Not enough space to cache rdd_126_16 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:56:33 WARN MemoryStore: Not enough space to cache rdd_126_18 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:56:33 WARN MemoryStore: Not enough space to cache rdd_126_19 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:56:34 WARN MemoryStore: Not enough space to cache rdd_126_20 in memory! (computed 30.5 MiB so far)\n",
      "24/12/03 15:56:34 WARN MemoryStore: Not enough space to cache rdd_126_21 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:56:34 WARN MemoryStore: Not enough space to cache rdd_126_23 in memory! (computed 8.1 MiB so far)\n",
      "24/12/03 15:56:34 WARN MemoryStore: Not enough space to cache rdd_126_24 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:56:34 WARN MemoryStore: Not enough space to cache rdd_126_25 in memory! (computed 32.0 MiB so far)\n",
      "24/12/03 15:56:34 WARN MemoryStore: Not enough space to cache rdd_126_27 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:56:34 WARN MemoryStore: Not enough space to cache rdd_126_28 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:56:35 WARN MemoryStore: Not enough space to cache rdd_126_29 in memory! (computed 15.9 MiB so far)\n",
      "24/12/03 15:56:35 WARN MemoryStore: Not enough space to cache rdd_126_30 in memory! (computed 30.3 MiB so far)\n",
      "24/12/03 15:56:35 WARN MemoryStore: Not enough space to cache rdd_126_32 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:56:35 WARN MemoryStore: Not enough space to cache rdd_126_33 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:56:35 WARN MemoryStore: Not enough space to cache rdd_126_35 in memory! (computed 31.9 MiB so far)\n",
      "24/12/03 15:56:35 WARN MemoryStore: Not enough space to cache rdd_126_36 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:56:36 WARN MemoryStore: Not enough space to cache rdd_126_37 in memory! (computed 8.2 MiB so far)\n",
      "24/12/03 15:56:36 WARN MemoryStore: Not enough space to cache rdd_126_39 in memory! (computed 30.3 MiB so far)\n",
      "24/12/03 15:56:36 WARN MemoryStore: Not enough space to cache rdd_126_40 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:56:36 WARN MemoryStore: Not enough space to cache rdd_126_41 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:56:36 WARN MemoryStore: Not enough space to cache rdd_126_42 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:56:37 WARN MemoryStore: Not enough space to cache rdd_126_43 in memory! (computed 30.4 MiB so far)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "currency_index = StringIndexer(inputCol=\"Receiving_Currency\", outputCol=\"CurrencyIndex\")\n",
    "payment_format_index = StringIndexer(inputCol=\"Payment_Format\", outputCol=\"PaymentFormatIndex\")\n",
    "pattern_type_index = StringIndexer(inputCol=\"Pattern_Type\", outputCol=\"PatternTypeIndex\")\n",
    "\n",
    "featured_df = currency_index.fit(featured_df).transform(featured_df)\n",
    "featured_df = payment_format_index.fit(featured_df).transform(featured_df)\n",
    "featured_df = pattern_type_index.fit(featured_df).transform(featured_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:56:37.558294Z",
     "iopub.status.busy": "2024-12-03T15:56:37.557834Z",
     "iopub.status.idle": "2024-12-03T15:59:25.204833Z",
     "shell.execute_reply": "2024-12-03T15:59:25.201278Z",
     "shell.execute_reply.started": "2024-12-03T15:56:37.558243Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:56:44 WARN MemoryStore: Not enough space to cache rdd_126_5 in memory! (computed 31.1 MiB so far)\n",
      "24/12/03 15:56:44 WARN MemoryStore: Not enough space to cache rdd_126_6 in memory! (computed 15.9 MiB so far)\n",
      "24/12/03 15:56:44 WARN MemoryStore: Not enough space to cache rdd_126_7 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:56:48 WARN MemoryStore: Not enough space to cache rdd_126_8 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:56:49 WARN MemoryStore: Not enough space to cache rdd_126_10 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:56:49 WARN MemoryStore: Not enough space to cache rdd_126_11 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:56:53 WARN MemoryStore: Not enough space to cache rdd_126_12 in memory! (computed 31.9 MiB so far)\n",
      "24/12/03 15:56:53 WARN MemoryStore: Not enough space to cache rdd_126_13 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:56:53 WARN MemoryStore: Not enough space to cache rdd_126_14 in memory! (computed 8.2 MiB so far)\n",
      "24/12/03 15:56:54 WARN MemoryStore: Not enough space to cache rdd_126_15 in memory! (computed 8.1 MiB so far)\n",
      "24/12/03 15:56:58 WARN MemoryStore: Not enough space to cache rdd_126_16 in memory! (computed 30.4 MiB so far)\n",
      "24/12/03 15:56:59 WARN MemoryStore: Not enough space to cache rdd_126_17 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:56:59 WARN MemoryStore: Not enough space to cache rdd_126_18 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:56:59 WARN MemoryStore: Not enough space to cache rdd_126_19 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:57:04 WARN MemoryStore: Not enough space to cache rdd_126_20 in memory! (computed 30.5 MiB so far)\n",
      "24/12/03 15:57:05 WARN MemoryStore: Not enough space to cache rdd_126_21 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:57:06 WARN MemoryStore: Not enough space to cache rdd_126_23 in memory! (computed 8.1 MiB so far)\n",
      "24/12/03 15:57:09 WARN MemoryStore: Not enough space to cache rdd_126_24 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:57:12 WARN MemoryStore: Not enough space to cache rdd_126_25 in memory! (computed 32.0 MiB so far)\n",
      "24/12/03 15:57:13 WARN MemoryStore: Not enough space to cache rdd_126_27 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:57:17 WARN MemoryStore: Not enough space to cache rdd_126_28 in memory! (computed 15.7 MiB so far)\n",
      "24/12/03 15:57:18 WARN MemoryStore: Not enough space to cache rdd_126_29 in memory! (computed 30.8 MiB so far)\n",
      "24/12/03 15:57:18 WARN MemoryStore: Not enough space to cache rdd_126_30 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:57:22 WARN MemoryStore: Not enough space to cache rdd_126_32 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:57:22 WARN MemoryStore: Not enough space to cache rdd_126_33 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:57:24 WARN MemoryStore: Not enough space to cache rdd_126_35 in memory! (computed 16.1 MiB so far)\n",
      "24/12/03 15:57:26 WARN MemoryStore: Not enough space to cache rdd_126_36 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:57:27 WARN MemoryStore: Not enough space to cache rdd_126_37 in memory! (computed 31.2 MiB so far)\n",
      "24/12/03 15:57:28 WARN MemoryStore: Not enough space to cache rdd_126_39 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:57:31 WARN MemoryStore: Not enough space to cache rdd_126_40 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:57:31 WARN MemoryStore: Not enough space to cache rdd_126_41 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:57:32 WARN MemoryStore: Not enough space to cache rdd_126_42 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:57:33 WARN MemoryStore: Not enough space to cache rdd_126_43 in memory! (computed 8.1 MiB so far)\n",
      "[Stage 70:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+----+---------+------+-----+------------------+-------------+------------------+----------------+\n",
      "|Timestamp          |From_Bank|From_Account|To_Bank|To_Account|Amount_Received|Receiving_Currency|Amount_Paid|Payment_Currency|Payment_Format|Pattern_Type|isLaundering|Hour|DayOfWeek|FanOut|FanIn|AvgAmountSent     |CurrencyIndex|PaymentFormatIndex|PatternTypeIndex|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+----+---------+------+-----+------------------+-------------+------------------+----------------+\n",
      "|2022-09-01 05:21:00|004      |800060A20   |004    |800060A20 |1834.72        |Rupee             |1834.72    |Rupee           |Reinvestment  |Unknown     |0           |5   |5        |228   |53   |157083.68798252573|5.0          |4.0               |0.0             |\n",
      "|2022-09-07 23:10:00|004      |800060A20   |025    |8129D4D00 |922259.2       |Rupee             |922259.2   |Rupee           |ACH           |Unknown     |0           |23  |4        |228   |16   |157083.68798252573|5.0          |2.0               |0.0             |\n",
      "|2022-09-16 07:14:00|004      |800060A20   |004    |800060A20 |21381.18       |Rupee             |21381.18   |Rupee           |Cheque        |Unknown     |0           |7   |6        |228   |53   |157083.68798252573|5.0          |0.0               |0.0             |\n",
      "|2022-09-08 07:24:00|004      |800060A20   |025    |8129D4D00 |922259.2       |Rupee             |922259.2   |Rupee           |ACH           |Unknown     |0           |7   |5        |228   |16   |157083.68798252573|5.0          |2.0               |0.0             |\n",
      "|2022-09-01 05:55:00|004      |800060A20   |004    |800060A20 |21381.18       |Rupee             |21381.18   |Rupee           |Cheque        |Unknown     |0           |5   |5        |228   |53   |157083.68798252573|5.0          |0.0               |0.0             |\n",
      "|2022-09-09 22:58:00|004      |800060A20   |025    |8129D4D00 |595031.7       |Rupee             |595031.7   |Rupee           |Cheque        |Unknown     |0           |22  |6        |228   |16   |157083.68798252573|5.0          |0.0               |0.0             |\n",
      "|2022-09-01 05:46:00|004      |800060A20   |004    |800060A20 |10683.91       |Rupee             |10683.91   |Rupee           |Credit Card   |Unknown     |0           |5   |5        |228   |53   |157083.68798252573|5.0          |1.0               |0.0             |\n",
      "|2022-09-10 01:03:00|004      |800060A20   |025    |8129D4D00 |922259.2       |Rupee             |922259.2   |Rupee           |ACH           |Unknown     |0           |1   |7        |228   |16   |157083.68798252573|5.0          |2.0               |0.0             |\n",
      "|2022-09-01 05:53:00|004      |800060A20   |004    |800060A20 |11860.6        |Rupee             |11860.6    |Rupee           |Wire          |Unknown     |0           |5   |5        |228   |53   |157083.68798252573|5.0          |5.0               |0.0             |\n",
      "|2022-09-01 12:24:00|004      |800060A20   |025    |8129D4D00 |595031.7       |Rupee             |595031.7   |Rupee           |Cheque        |Unknown     |0           |12  |5        |228   |16   |157083.68798252573|5.0          |0.0               |0.0             |\n",
      "|2022-09-02 07:16:00|004      |800060A20   |004    |800060A20 |10683.91       |Rupee             |10683.91   |Rupee           |Credit Card   |Unknown     |0           |7   |6        |228   |53   |157083.68798252573|5.0          |1.0               |0.0             |\n",
      "|2022-09-12 10:27:00|004      |800060A20   |025    |8129D4D00 |595031.7       |Rupee             |595031.7   |Rupee           |Cheque        |Unknown     |0           |10  |2        |228   |16   |157083.68798252573|5.0          |0.0               |0.0             |\n",
      "|2022-09-02 07:18:00|004      |800060A20   |004    |800060A20 |11860.6        |Rupee             |11860.6    |Rupee           |Wire          |Unknown     |0           |7   |6        |228   |53   |157083.68798252573|5.0          |5.0               |0.0             |\n",
      "|2022-09-02 05:20:00|004      |800060A20   |025    |8129D4D00 |595031.7       |Rupee             |595031.7   |Rupee           |Cheque        |Unknown     |0           |5   |6        |228   |16   |157083.68798252573|5.0          |0.0               |0.0             |\n",
      "|2022-09-05 19:53:00|004      |800060A20   |004    |800060A20 |3117.27        |Euro              |268273.75  |Rupee           |ACH           |STACK       |1           |19  |2        |228   |53   |157083.68798252573|1.0          |2.0               |1.0             |\n",
      "|2022-09-02 05:01:00|004      |800060A20   |025    |8129D4D00 |922259.2       |Rupee             |922259.2   |Rupee           |ACH           |Unknown     |0           |5   |6        |228   |16   |157083.68798252573|5.0          |2.0               |0.0             |\n",
      "|2022-09-07 13:32:00|004      |800060A20   |004    |800060A20 |21381.18       |Rupee             |21381.18   |Rupee           |Cheque        |Unknown     |0           |13  |4        |228   |53   |157083.68798252573|5.0          |0.0               |0.0             |\n",
      "|2022-09-13 08:23:00|004      |800060A20   |025    |8129D4D00 |595031.7       |Rupee             |595031.7   |Rupee           |Cheque        |Unknown     |0           |8   |3        |228   |16   |157083.68798252573|5.0          |0.0               |0.0             |\n",
      "|2022-09-07 13:36:00|004      |800060A20   |004    |800060A20 |10683.91       |Rupee             |10683.91   |Rupee           |Credit Card   |Unknown     |0           |13  |4        |228   |53   |157083.68798252573|5.0          |1.0               |0.0             |\n",
      "|2022-09-03 12:18:00|004      |800060A20   |025    |8129D4D00 |595031.7       |Rupee             |595031.7   |Rupee           |Cheque        |Unknown     |0           |12  |7        |228   |16   |157083.68798252573|5.0          |0.0               |0.0             |\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+------------+------------+----+---------+------+-----+------------------+-------------+------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show the resulting DataFrame\n",
    "featured_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic data for minority, using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:59:25.209428Z",
     "iopub.status.busy": "2024-12-03T15:59:25.206758Z",
     "iopub.status.idle": "2024-12-03T16:04:59.936742Z",
     "shell.execute_reply": "2024-12-03T16:04:59.934269Z",
     "shell.execute_reply.started": "2024-12-03T15:59:25.209354Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 15:59:31 WARN MemoryStore: Not enough space to cache rdd_126_6 in memory! (computed 31.0 MiB so far)\n",
      "24/12/03 15:59:31 WARN MemoryStore: Not enough space to cache rdd_126_7 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:59:34 WARN MemoryStore: Not enough space to cache rdd_126_8 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 15:59:35 WARN MemoryStore: Not enough space to cache rdd_126_9 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:59:35 WARN MemoryStore: Not enough space to cache rdd_126_11 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:59:35 WARN MemoryStore: Not enough space to cache rdd_126_10 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:59:38 WARN MemoryStore: Not enough space to cache rdd_126_12 in memory! (computed 31.9 MiB so far)\n",
      "24/12/03 15:59:39 WARN MemoryStore: Not enough space to cache rdd_126_14 in memory! (computed 8.2 MiB so far)\n",
      "24/12/03 15:59:39 WARN MemoryStore: Not enough space to cache rdd_126_13 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:59:39 WARN MemoryStore: Not enough space to cache rdd_126_15 in memory! (computed 8.1 MiB so far)\n",
      "24/12/03 15:59:42 WARN MemoryStore: Not enough space to cache rdd_126_16 in memory! (computed 30.4 MiB so far)\n",
      "24/12/03 15:59:43 WARN MemoryStore: Not enough space to cache rdd_126_17 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 15:59:43 WARN MemoryStore: Not enough space to cache rdd_126_18 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:59:43 WARN MemoryStore: Not enough space to cache rdd_126_19 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:59:46 WARN MemoryStore: Not enough space to cache rdd_126_20 in memory! (computed 30.5 MiB so far)\n",
      "24/12/03 15:59:46 WARN MemoryStore: Not enough space to cache rdd_126_21 in memory! (computed 15.5 MiB so far)\n",
      "24/12/03 15:59:47 WARN MemoryStore: Not enough space to cache rdd_126_23 in memory! (computed 8.1 MiB so far)\n",
      "24/12/03 15:59:49 WARN MemoryStore: Not enough space to cache rdd_126_24 in memory! (computed 16.3 MiB so far)\n",
      "24/12/03 15:59:50 WARN MemoryStore: Not enough space to cache rdd_126_25 in memory! (computed 32.0 MiB so far)\n",
      "24/12/03 15:59:50 WARN MemoryStore: Not enough space to cache rdd_126_27 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 15:59:53 WARN MemoryStore: Not enough space to cache rdd_126_28 in memory! (computed 15.7 MiB so far)\n",
      "24/12/03 15:59:53 WARN MemoryStore: Not enough space to cache rdd_126_29 in memory! (computed 30.8 MiB so far)\n",
      "24/12/03 15:59:54 WARN MemoryStore: Not enough space to cache rdd_126_30 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 15:59:58 WARN MemoryStore: Not enough space to cache rdd_126_32 in memory! (computed 30.3 MiB so far)\n",
      "24/12/03 15:59:58 WARN MemoryStore: Not enough space to cache rdd_126_33 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 15:59:59 WARN MemoryStore: Not enough space to cache rdd_126_35 in memory! (computed 8.3 MiB so far)\n",
      "24/12/03 16:00:02 WARN MemoryStore: Not enough space to cache rdd_126_36 in memory! (computed 31.7 MiB so far)\n",
      "24/12/03 16:00:02 WARN MemoryStore: Not enough space to cache rdd_126_37 in memory! (computed 15.9 MiB so far)\n",
      "24/12/03 16:00:03 WARN MemoryStore: Not enough space to cache rdd_126_39 in memory! (computed 8.0 MiB so far)\n",
      "24/12/03 16:00:06 WARN MemoryStore: Not enough space to cache rdd_126_40 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 16:00:06 WARN MemoryStore: Not enough space to cache rdd_126_41 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 16:00:06 WARN MemoryStore: Not enough space to cache rdd_126_42 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 16:00:07 WARN MemoryStore: Not enough space to cache rdd_126_43 in memory! (computed 8.1 MiB so far)\n",
      "24/12/03 16:04:13 WARN MemoryStore: Not enough space to cache rdd_126_6 in memory! (computed 31.0 MiB so far)\n",
      "24/12/03 16:04:13 WARN MemoryStore: Not enough space to cache rdd_126_7 in memory! (computed 15.3 MiB so far)\n",
      "24/12/03 16:04:19 WARN MemoryStore: Not enough space to cache rdd_126_8 in memory! (computed 30.2 MiB so far)\n",
      "24/12/03 16:04:19 WARN MemoryStore: Not enough space to cache rdd_126_9 in memory! (computed 15.4 MiB so far)\n",
      "24/12/03 16:04:19 WARN MemoryStore: Not enough space to cache rdd_126_10 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 16:04:19 WARN MemoryStore: Not enough space to cache rdd_126_11 in memory! (computed 7.9 MiB so far)\n",
      "24/12/03 16:04:31 WARN MemoryStore: Not enough space to cache rdd_126_12 in memory! (computed 31.9 MiB so far)\n",
      "24/12/03 16:04:31 WARN MemoryStore: Not enough space to cache rdd_126_14 in memory! (computed 16.0 MiB so far)\n",
      "24/12/03 16:04:31 WARN MemoryStore: Not enough space to cache rdd_126_13 in memory! (computed 8.4 MiB so far)\n",
      "24/12/03 16:04:32 WARN MemoryStore: Not enough space to cache rdd_126_15 in memory! (computed 8.1 MiB so far)\n",
      "24/12/03 16:04:58 ERROR Executor: Exception in task 12.0 in stage 81.0 (TID 706)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.unsafe.types.UTF8String.fromAddress(UTF8String.java:132)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.getUTF8String(UnsafeRow.java:382)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:168)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2483/0x0000000840fcf040.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/12/03 16:04:58 ERROR Executor: Exception in task 15.0 in stage 81.0 (TID 709)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.unsafe.types.UTF8String.fromBytes(UTF8String.java:122)\n",
      "\tat org.apache.spark.sql.execution.columnar.STRING$.extract(ColumnType.scala:510)\n",
      "\tat org.apache.spark.sql.execution.columnar.STRING$.extract(ColumnType.scala:494)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.DictionaryEncoding$Decoder.$anonfun$new$3(compressionSchemes.scala:476)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.DictionaryEncoding$Decoder$$Lambda$4309/0x000000084167f040.apply$mcVI$sp(Unknown Source)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.DictionaryEncoding$Decoder.<init>(compressionSchemes.scala:475)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.DictionaryEncoding$.decoder(compressionSchemes.scala:367)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.DictionaryEncoding$.decoder(compressionSchemes.scala:359)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.CompressibleColumnAccessor.initialize(CompressibleColumnAccessor.scala:32)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.CompressibleColumnAccessor.initialize$(CompressibleColumnAccessor.scala:30)\n",
      "\tat org.apache.spark.sql.execution.columnar.NativeColumnAccessor.initialize(ColumnAccessor.scala:75)\n",
      "\tat org.apache.spark.sql.execution.columnar.ColumnAccessor.$init$(ColumnAccessor.scala:40)\n",
      "\tat org.apache.spark.sql.execution.columnar.BasicColumnAccessor.<init>(ColumnAccessor.scala:54)\n",
      "\tat org.apache.spark.sql.execution.columnar.NativeColumnAccessor.<init>(ColumnAccessor.scala:78)\n",
      "\tat org.apache.spark.sql.execution.columnar.StringColumnAccessor.<init>(ColumnAccessor.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificColumnarIterator.hasNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:168)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2483/0x0000000840fcf040.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "24/12/03 16:04:58 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 12.0 in stage 81.0 (TID 706),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.unsafe.types.UTF8String.fromAddress(UTF8String.java:132)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.getUTF8String(UnsafeRow.java:382)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:168)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2483/0x0000000840fcf040.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/12/03 16:04:58 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 15.0 in stage 81.0 (TID 709),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.unsafe.types.UTF8String.fromBytes(UTF8String.java:122)\n",
      "\tat org.apache.spark.sql.execution.columnar.STRING$.extract(ColumnType.scala:510)\n",
      "\tat org.apache.spark.sql.execution.columnar.STRING$.extract(ColumnType.scala:494)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.DictionaryEncoding$Decoder.$anonfun$new$3(compressionSchemes.scala:476)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.DictionaryEncoding$Decoder$$Lambda$4309/0x000000084167f040.apply$mcVI$sp(Unknown Source)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.DictionaryEncoding$Decoder.<init>(compressionSchemes.scala:475)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.DictionaryEncoding$.decoder(compressionSchemes.scala:367)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.DictionaryEncoding$.decoder(compressionSchemes.scala:359)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.CompressibleColumnAccessor.initialize(CompressibleColumnAccessor.scala:32)\n",
      "\tat org.apache.spark.sql.execution.columnar.compression.CompressibleColumnAccessor.initialize$(CompressibleColumnAccessor.scala:30)\n",
      "\tat org.apache.spark.sql.execution.columnar.NativeColumnAccessor.initialize(ColumnAccessor.scala:75)\n",
      "\tat org.apache.spark.sql.execution.columnar.ColumnAccessor.$init$(ColumnAccessor.scala:40)\n",
      "\tat org.apache.spark.sql.execution.columnar.BasicColumnAccessor.<init>(ColumnAccessor.scala:54)\n",
      "\tat org.apache.spark.sql.execution.columnar.NativeColumnAccessor.<init>(ColumnAccessor.scala:78)\n",
      "\tat org.apache.spark.sql.execution.columnar.StringColumnAccessor.<init>(ColumnAccessor.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificColumnarIterator.hasNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:168)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2483/0x0000000840fcf040.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "24/12/03 16:04:58 ERROR Inbox: Ignoring error\n",
      "java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@531dc2a0 rejected from java.util.concurrent.ThreadPoolExecutor@49ce2afa[Shutting down, pool size = 3, active threads = 3, queued tasks = 0, completed tasks = 707]\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)\n",
      "\tat org.apache.spark.executor.Executor.launchTask(Executor.scala:363)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1(LocalSchedulerBackend.scala:93)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1$adapted(LocalSchedulerBackend.scala:91)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:91)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:74)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/12/03 16:04:58 WARN TaskSetManager: Lost task 12.0 in stage 81.0 (TID 706) (5043e306571c executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.unsafe.types.UTF8String.fromAddress(UTF8String.java:132)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.getUTF8String(UnsafeRow.java:382)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:168)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2483/0x0000000840fcf040.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "24/12/03 16:04:58 ERROR TaskSetManager: Task 12 in stage 81.0 failed 1 times; aborting job\n",
      "[Stage 81:==============>                                         (12 + 5) / 46]\r"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o493.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 81.0 failed 1 times, most recent failure: Lost task 12.0 in stage 81.0 (TID 706) (5043e306571c executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.unsafe.types.UTF8String.fromAddress(UTF8String.java:132)\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.getUTF8String(UnsafeRow.java:382)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:168)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2483/0x0000000840fcf040.apply(Unknown Source)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.unsafe.types.UTF8String.fromAddress(UTF8String.java:132)\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.getUTF8String(UnsafeRow.java:382)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:168)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2483/0x0000000840fcf040.apply(Unknown Source)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m balanced_featured_df \u001b[38;5;241m=\u001b[39m majority_df\u001b[38;5;241m.\u001b[39munion(synthetic_df)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Display counts to confirm balancing\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[43mbalanced_featured_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43misLaundering\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/sql/dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/sql/dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    962\u001b[0m     )\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o493.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 81.0 failed 1 times, most recent failure: Lost task 12.0 in stage 81.0 (TID 706) (5043e306571c executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.unsafe.types.UTF8String.fromAddress(UTF8String.java:132)\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.getUTF8String(UnsafeRow.java:382)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:168)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2483/0x0000000840fcf040.apply(Unknown Source)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.unsafe.types.UTF8String.fromAddress(UTF8String.java:132)\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.getUTF8String(UnsafeRow.java:382)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:168)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2483/0x0000000840fcf040.apply(Unknown Source)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Select only the required columns (excluding 'isLaundering')\n",
    "feature_columns = [\"Amount_Received\", \"FanOut\", \"FanIn\", \"AvgAmountSent\",\n",
    "                   \"Hour\", \"DayOfWeek\", \"CurrencyIndex\",\n",
    "                   \"PaymentFormatIndex\", \"PatternTypeIndex\"]\n",
    "\n",
    "# Select features for minority class (isLaundering = 1)\n",
    "minority_df = featured_df.filter(F.col(\"isLaundering\") == 1).select(*feature_columns)\n",
    "majority_df = featured_df.filter(F.col(\"isLaundering\") == 0).select(*feature_columns, \"isLaundering\")\n",
    "\n",
    "featured_df.unpersist()\n",
    "\n",
    "# Step 2: Define a function to generate synthetic samples (excluding isLaundering)\n",
    "def generate_synthetic_samples(minority_data, num_samples=10):\n",
    "    synthetic_samples = []\n",
    "\n",
    "    for row in minority_data:\n",
    "        base_vector = np.array([row[col] for col in feature_columns])\n",
    "\n",
    "        # Find random neighbors within the minority class\n",
    "        neighbors = random.sample(minority_data, k=num_samples)\n",
    "        for neighbor in neighbors:\n",
    "            neighbor_vector = np.array([neighbor[col] for col in feature_columns])\n",
    "\n",
    "            # Interpolate to create a synthetic sample\n",
    "            gap = np.random.rand()\n",
    "            synthetic_vector = base_vector + gap * (neighbor_vector - base_vector)\n",
    "\n",
    "            # Append the synthetic sample without the 'isLaundering' column\n",
    "            synthetic_samples.append(tuple(synthetic_vector.tolist()))\n",
    "\n",
    "    return synthetic_samples\n",
    "\n",
    "# Step 3: Collect minority samples and generate synthetic samples\n",
    "minority_data = minority_df.collect()\n",
    "synthetic_samples = generate_synthetic_samples(minority_data, num_samples=50)\n",
    "\n",
    "# Step 4: Define schema for synthetic samples without 'isLaundering'\n",
    "schema = StructType([StructField(col, DoubleType(), True) for col in feature_columns])\n",
    "\n",
    "# Create synthetic DataFrame from synthetic samples\n",
    "synthetic_df = spark.createDataFrame(synthetic_samples, schema=schema)\n",
    "\n",
    "# Step 5: Add 'isLaundering' column with value 1 to synthetic samples\n",
    "synthetic_df = synthetic_df.withColumn(\"isLaundering\", F.lit(1))\n",
    "\n",
    "# Step 6: Combine the majority and synthetic DataFrames\n",
    "balanced_featured_df = majority_df.union(synthetic_df)\n",
    "\n",
    "# Display counts to confirm balancing\n",
    "balanced_featured_df.cache().groupBy(\"isLaundering\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2948142,
     "sourceId": 5080714,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
